so hello everyone welcome back to the fourth lecture of this week in last lecture we had discussed what is pcfgs and we we finally came up with what are the interesting problems that that we would like to answer so for example what is the most likely parse for a given sentence as per my pcfg grammar and what is the probability of the sentence as per the grammar finally we also wanted to see how do i learn my pcfg rule probabilities ok if you remember this was the only difference between context free grammar and the probabilities version is that all the production rules here have a probability value so how do i learn these values so this is what we will be covering in this lecture and in the next lecture and we will be using a specific concept called called inside outside probabilities ok and this will be very analogous to what you studied in forward backward algorithm in in terms of learning parameters for h m m so we will go to that so we so starting with the first problem how do i find out the most likely parse for a sentence and this can be solved simply if we use the c k y algorithm for pcfg ok so from the example that we did in the last class i hope you you understand now how to use c k y algorithm for the context free grammar so today i will show how do you extend that for p c f g so let us take an example so we have this pcfg so what you are seeing here with each rule you have a rule probability as well ok and and you can verify that all the probabilities starting from a given right hand side will add up to one so now i want to find out what is the most likely parse for the sentence the same sentence the pilot likes flying planes so for that i need to find out what is the probability with which i can find a non terminal as in the final position for deriving this whole sentence zero to five so we proceed nearly in the same manner as we did ah in the in the case of c k y ok so what i will do i just take the same example how we solve c k y in addition and what are the things that you need to do different here so this is what we had seen last time so if you have to build a if you have to find out what is the whether the sentence can derive this whole thing i fill it starting from zero one one two two three three four four five then i will go further so now i just tell what is what will differ in the case of pcfg so now with each non terminal there will be probability with which it can derive that particular terminal or a set of terminals so it is starting from the first element so this says that the non terminal dt derives a now i will write down here what is the probability ok so if you go to your grammar the probability dt gives me a it's point three so i will put point three here similarly for this element what is the probability that n n gives me pilot and if i look at my grammar this is point one similarly here what is the probability that vbz derives likes this gives me point four and like that i will fill all these entries now this is ok now what i want to show you is that how do i fill the next entry that is zero two what is the probability with which the non terminal n p derives the sequence a pilot now if you remember a single non terminal can derive two non terminals two terminals only via two non terminals so it has to first derive x zero one x one two then each will individually derive an pilot so how do i fill in this probability value so this would be probability that n p derives d t n n times probability dt derives a times probability n n derives pilot ok this probability getting my pcfg so this probability if i see in my grammar this is point three this probability i have already filled in is point three and this probability also i have filled in this is point one so the probability that n p derives a pilot here comes out to be nine times ten to the power minus three and that's what i fill in here ok and in the same manner you will fill in all the entries if it is five it means the probability will be zero ok and if there is a non terminal here that means there will be certain probabilities and this you can get by finding out probability individually for each of this and multiplying the probability of this rule so that way you can incrementally built all the stable from in a bottom up fashion we are starting from the first element then in the next one and so on ok so remember nearly same as we did in the last class only the the probabilities and the multifunctional probabilities will change suppose you do that for this example this is what you will find out so these are the rule probabilities that you will come up with so i will i will encourage all of you that you should try this on your own and see that you can get the same set of values that have been shown in the slide so now coming to the next question i am given the pcfg as my grammar how do i find out what is the probability of the sentence ok so one simple solution you can always find is that i find out all the possible parse trees find the probabilities for each of the parse trees and add those up that is one way ok but this you might be inefficient if there are very huge number of parses trees if you remember one of the introductory slides we said that as you increase the number of words in the sentence or the number of phrases the number of possible parses increase roughly exponentially ok there was something like peclet number with this their group and it can go go two hundred plus parses so you don't want to sum this get the probability individually and then do addition you want to do something more efficient than that and how do we do this and that's why we use this inside algorithm ok that is one of the main topics of this lecture so what is the inside algorithm and this is some dynamic programming algorithm based on the concept of inside outside probabilities so now i will i will try to introduce what is that inside outside probability so this this is very centre to understanding this lecture as well as the next lecture so so let us try to understand what is the concept ok and just so that it it helps you this is very very similar to the concept of forward backward algorithm that we did in the case of h m f s so what is inside outside probabilities so i can this is parameterized for certain node of my tree so what you see in this figure i have a sentence with words w one to w m ok and n one is the non terminal you can think of it as the sentence non terminal that derives the whole sequence of words using my grammar now i am putting a parameter here that is n j n j is one particular non terminal it can be n p v p or so on so what i am saying here assume that there is a non terminal n j that derives the sequence w p to w q ok again p and q are arbitrary you can take any p starting from one to m minus one ok so what i am parameterized here is that this n j derives the sequence w p to w q so now with respect to that i am defining what is my inside probabilities and what is my outside probabilities so you can as such you can guess this is something outside of that and this is something inside of that so how do i define my inside and outside probabilities so outside probability is that it is starting from n one i can derive the sequence w one to w p minus one i can derive this non terminal w sorry n j and the sequence w q plus one to w m this is my outside probability and inside probability is given this n j the probability that i can derive w p to w q as per my grammar ok and it will then follow the same sort of ideas that if i can multiply inside and outside probability that will give me something like the probability of the sentence parameterized by this particular jth non terminal so formally that's how i can write the outside and inside probabilities outside probability alpha j p q that is standard format which we can write p q denotes the sequence w p w q on which this parameterized and j denotes the particular non terminal n j here so the outside probabilities probability of generating w one to w p minus one yes and j p q and w q plus one to m given by grammar and inside probabilities probability of generating w p to w q given n j ok so this is also parameterized by n j p q because it is arriving w p to w q and in my grammar so that's why i define my inside and outside probabilities now let us take a simple example i have the sentence the gunman sprayed the building with bullets ok and here your p q is four and five so you are parameterization with respect to this sequence the building ok so accordingly this will be particular non terminal that is n p that is deriving the building so now what do we mean by inside probability so inside probabilities what is the probability that this non terminal n p at this location derives the sequence the building this is my inside probability ok and what will be the outside probability here that is starting from n one i can derive the sequence the gunman is sprayed this n p and with bullets this is my outside probability ok so yeah so this is what we have defined the outside probability alpha n p four five would be the probability of this sequence the gunman is sprayed n p four five and with bullets given my grammar and the inside probability beta n p four five would be the probability for deriving the building given n p four five and grammar now this is this definition of inside and outside probabilities now how do i actually compute this inside and outside probability given this sentence and suppose our grammar is also given to me how do i compute that so for inside probability so let us see this is the definition of inside probability beta j p q is probability of deriving the sequence w p to w q given non terminal n j p q in my grammar now so i am i will be deriving both these probabilities in a iterative manner so what will be the base case here so the base case here if you see would be when p and q are same that is i am deriving a single terminal from a non terminal ok and that you can find out very easily if your grammar is in the chomsky normal form so what is the particular non terminal that derives this term so this would be the base case for deriving a single term base and then i will go in a bottom up fashion derive the inside probabilities for higher and higher sequences so the base case here is when p is equal to q so beta j k k would be probability of w k k given n j k k and g now w k k is a single word ok sequence from k to k and i can immediately find out what is the role in my grammar that derives this word w k k and i put this rule probability here and this will give me the this probability beta j k k now as an example suppose here my word is building ok so this is the fifth word so i am computing beta for five five and suppose i take n j is equal to n n that works in non terminal derives this word so you can compute beta n n five five as the probability with which the non terminal n n can derive this word building ok and this is easily given by my grammar so this is my base case now what will be the inductive case so i have to go bottom up so lets take a generic beta j p q how do i derive it in terms of the smaller values so let us try to do that so if i am given i have to compute beta j p q what is that mean it means that i have a non terminal n j and that is deriving a sequence w p up to w q ok and i have to compute this probability given n j the probability of the sequence w p to w q because i am conducting in a i am doing it in a bottom fashion and i have to use the proper lower values so i will first say n j can give me some n r and n s now n r will derive from w p to some w d so very generic case so this can be any possible n r and n s that my n j can derive and again i can go from w p to any w d so you can see what can d vary from to so d can vary from p up to q minus one ok and this n s gives me w d plus one up to w q this is my recursive case ok now how do i write down this probability so i will say this is first the probability that n j derives the rule the non terminal the n r and n s so probability n j derives n r n s times this probability now here n r is given so what is the probability is that n r given n r it derives from w p to w d again you can compute this using so you can express this using inside probability that is beta r p d similarly this one beta s d plus one to q ok now this is for the particular variation that i have shown but in general d can vary from p to q minus one and they can be any possible n r and n s so i will have to write down this whole thing let me call it x so i have to say this can vary from p to q minus one and all possible n r n s ok and i will put x here so this is my inductive step now what do i mean by parameterization over by all possible r s and all possible d so if you take the case of this simple phrase the huge building ok so what do i mean by various d so if i have this this is the huge building by variation of d i mean whether i am composing it by the huge and building or the and huge building two possible variables of d ok and what do i mean by parameterization over all possible n r and n s so that the particular non terminal that derives this whole thing can be support this n p it can come via say n p gives me d t n n this is one possibility this is dtnn this is and or we can make n p gives me d t n n s this is another possibility so this is the parameterization over all possible n r n s and this is over out possible d's so now we have seen that you can compute it for the only the terminals first and then the bottom up to compute it for other values ok so now if you do a simple example so this is again similar to what we have seen earlier so i am given this pcfg and this is my sentence and i want to compute the inside probabilities here so how do i go about out it and you looking at the table you can see that we will doing something very similar to what we did in the case of c k y algorithm ok but now we will focus on filling up what is the inside probability of deriving this from the particular non terminal ok so let us just try to filling some entries here ok let me lets try only the first two this is astronomers and this is saw ok and i have to fill in the inside probabilities so this would be so now in the in the in the way we defined inside probability this would be one one this would be two two sequence from word two to word two this would be sequence from word one to word two so now when i define beta j p q so here p and q are both one so i have to find out what is the non terminal that derives this word astronomers now if i see a grammar and these derive astronomers with the probability of point one so i can fill fill the inside probability here beta n p one one one one you need not to write and i am just writing here is equal to point one ok because one one is already defined by the particular cell where we are similarly let us go to two two two two is saw if i see the grammar n p derives saw n p derives saw ok so there are two different so that's where you can see there are two different j that are possible here so one is beta v another is beta n p and this has the probability of one and this has the probability of zero point zero four using my grammar now suppose i have to fill this one one two what is the particular non terminal that will derive this this whole thing again similar to what we were doing in c k y is the something that derives n p and n p if i see my grammar nothing derives n p and n p ok in the right hand side now is there something that derives n p followed by v or again there is nothing here n p followed by v so this will come out to be zero ok suppose there was something that derives n p followed by v so i would simplify find out what is the non terminal that is deriving this and put the probability as this times this times the rule probability ok similar to what we were doing in the case of c k y for probability context free grammars the only difference here is that if there are multiple splits for same non terminal i will add all these ok so so for example the same non terminal so i am taking a hypothetical case suppose the same non terminal x derives n p followed by v and also n p followed by n p if the probability of p one is the rule probability this is a probability of p two so i will put here beta x and this will be p one times zero point one times one plus p two times zero point one times zero point zero four and that's why i fill in all the entries ok so i will i will take care of all the possible ways in which this particular non terminal we can derive this ok so again so if you keep on doing that this is what you will see so we had filled in this entry and this entry and this entry but i will encourage you to fill in all the entries of this table and see if you can get to this particular term what is the probability of the sentence generating this whole thing ok so now if you see this table you also get the answer for the second question it how do i find out the probability of my sentence use the same probabilities and compute beta as for one to m or one to five in this case that will give you the probability of this whole sentence ok so this was about inside probabilities now how do i compute the outside probabilities ok so if you remember this is analogous to what we did in the case of forward backward algorithm so now inside probabilities we are computing bottom up and this will be computed top down and what will be the base case base case would be very very simple that is can i generate the whole sequence one to m ok and now because this is the grammatical sentence we are assuming so only the first non terminal that is sentence or you can write it as n one can derive this whole sentence nothing else can derive so that's why the base case will be alpha one one to m is one if the so this j is one otherwise it will be zero so if i write down alpha one one to m will be one and alpha j one to m will be zero if j is not equal to one if j is equal to one denotes the starting non terminal like s or n one whatever ah we were using the notation form so now this is the base case now what will be the inductive case so inductive case would be i have to compute it in a top down fashion ok so can you think of inductive case here so now what i am showing here what are the two possibilities of this inductive case so let me just show it quickly on the paper so i have to compute alpha j p q ok and i am going top down now what is the alpha j p q i have a non terminal n j that derives w p to w q ok and everything else w one to w p minus one and w q plus one to w m is there in the sentence now i have to do it in a top down manner so i have to use the probability from the upper label so i would say what is the non terminal that derives this n j with some other non terminal and again this can be either left child or right child lets take the case where it is the left child so i would say there is some non terminal n f it is starting from p up to you have to take some w e p e that derives n j and some n g and what is the parameters here this is p q this would be q plus one to e ok so this is deriving q plus one to e now i am doing it top down so i have already completed this that is the probability of this sequence this and w e plus one up to m this i have already obtained now what i have to obtained in alpha j p q is the probability of w one to w p minus p n j p q and w q plus one to w m this is what i have to obtain now here i have already obtained this probability and n f p e and somewhere w q plus one to w m this i have obtained so how do i write it in in this in terms of n f p e i will say this is n f p e ok although they may be different possible n f p e we will do the summation over that later times probability of this will probability n f gives you n j n g already we have come here and this is deriving w q plus one to w e because i need these probabilities also now now how do i how do i write down this expression this we just did in the previous case so this is nothing but the inside probability ok so this would be beta g q plus one to e ok and that gives me the probability for this particular extraction although there are various summations that we will have to do same case we can do for the when this is the right child then n g will come here and this is a huge very very similar ok so if you look at then in this case so this is where it is a left child this is where it is a right child in this case as we did it is alpha f p e probability of this rule and inside probability of this whole sequence and what are these summing over all the possible f and g's ok because it can be any non terminal that is arriving this n along with any other non terminal and what can what what is something else that can vary my e can vary from q plus one up to m so i am summing over all the possibilities and you can similarly see for the for the second case so now so so what is important here you can compute this outside probabilities by using inside probabilities on a that means you have to first compute the inside probabilities use that to compute the outside probabilities ok although computing outside probabilities much much more difficult than computing inside probability if you want to do that on paper that's why we did a example only for the inside probabilities now coming to this point so remember when i were saying that we have done this parameterization of inside and outside probabilities such that if we multiply that we had something interesting that we can use further and the goal here is also to compute the rule probabilities that is my third question i was asking that how do i compute my rule probabilities of pcfg we will come to that in the next lecture let us quickly see what do i get if i multiply the alpha j p q with beta j p q ok so if i do that so alpha j p g is nothing but probability of w one to w p minus one n j p q and w q plus one to m given my grammar and beta j p q is probability of w p q given and n j p q in the grammar so you multiply both of these you will see that w p q can come here and n p q is also retained here ok because here i need n j p q to be given that is already given to me before so this is the multiplication ok now what does this say so it is saying if i multiply alpha j p q with beta j p q i get the probability of generating this whole sequence of words w one to w m and that a non terminal n j derives w p to w q ok given my grammar now suppose i want to find out the probability that any possible non terminal derives from w p to w q there is some consistent spanning from w p w q in that case i will have to sum over all possible j's that i can achieve by summing over all possible j ` s for alpha j p q into beta j p q this is the probability of the sentence and that there is some consistent is spanning from the w word p to word q ok and this is you can write in this manner ok this is the same thing n one derives w one m and n p q derives w p q this and this are the same thing except this particular index of n j now if we go back to the previous example that we took what does that mean so probability is that this whole sentence the gunman sprayed the building with bullets and that there is some consistent spanning from word four to word five that means there is some non terminal they derive this sequence the word four to word five how do i obtain it this should be summation over all the possible non terminals n j such that this happens the gunman sprayed the building with bullets n j p q given g and this is nothing but alpha n p four five beta n p four five so here i am taking all possible j's j can be n p v p and so on so whatever non terminals so i multiply alpha beta for a particular j and add overall the possible j that gives me this probabilities so even here it may not be very very clear what is the actual use of obtaining this particular probability value ok how do i use it further and that is what we will see in the next lecture that how do i use this inside outside probability for learning the rule probabilities of my probabilistic context free grammatical ok so i hope this concept of inside outside probabilities is clear to you and then we can see how do use that further in the next class thank you