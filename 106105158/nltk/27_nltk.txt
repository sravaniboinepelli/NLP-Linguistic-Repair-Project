so welcome back for the sixth week of this course so so we had already started our discussion on what is parsing so this is the topic in syntax and we talked about a constituency parsing approach ok by using the probabilistic context free grammars so now we will use a slight different version of parsing is called dependency parsing so where ah instead of what we did in the case of constituency parsing where we were finding out what are the different word groups in terms of noun phrases adjective phrases verb phrases we will directly find out what is the relation between any two words in a sentence ok so dependency parsing notion has ah picked up a lot in in research field in the last few years but as such it is origin is is very very old many many different linguistic traditions for example in in ah for the sanskrit the famous sanskrit grammar [ FL ] that are the dependency relation between verb and different ah words in the sentences so for example if i have a sentence like ram eats apple a simple sentence i will see the verb eat is the main main verb here and what is the relation of ram so ram is subject of this verb and apple becomes an object of this verb ok so like that i am so here i am trying to directly say in this sentence if i am in different words are these related somehow and what is the relation between them so this is my dependency structure so in this lecture we will see what is the what is the formal way in which we can define dependency structure what are different linguistic constraints etcetera that we we need to impose in this structure and then we will start talking about the some of the models that are very popular for getting the dependency structure it's starting from the sentence so this kind of tree we have seen in the case of phrase structure also called the constituency structure so what we have seen here i have a sentence economic news had little effect on financial markets so they are different group of words as single unit so economic news make a noun phrase similarly this whole thing makes a verb phrase and they together make a sentence so like that what we have seen here which words are grouped together ok and how this whole sentence has been arranged that's what you see in a phrase structure now how dependency structure different so for the same sentence let us look at the dependency structure so here what are you seeing now this also looks like a tree but the nodes here are the words themselves not the phrases and different words has been have been connected by some edges and they label by some relation like had and news are connected and the relation is subject saying that news is a subject for the verb had similarly economic and news are related so this is economic is a noun modifier for the word news and so on lot of different words are connected in this sentence so in general what we are seeing two different words in a sentence are connected by certain relation and this is a directed sort of relation so economic and news are related by saying economic is a noun modifier for news so so in general how we can define a dependency structure so we take another sentence here he sent her a letter ok so what you are seeing here so first you are seeing some five six words or if you take the punctuation so they are five words as such he send her a letter five individual words so what do i do in dependency structure so we are connecting the word in the sentence by putting arrows between the words so i am putting an arrow between sent and he and these two are connected so he is a subject for sent similarly i am putting an arrow between sent and her so in that her is in indirect object for sent now what do these arrow show which arrows are showing means the relations between words and are also typed by some grammatical relation so they are saying these some relation and what is the relation it is the subject relation he is a subject for sent and what do these arrows connect they connect a head word like sent with a dependent word like he and there are some in linguistic there are some other terms like head can be called governor superior regent and the dependent can also be called a modifier inferior or subordinate and usually as you would see the dependency which will form a sort of tree structure now so what is important here so dependencies you have a head that connects to a dependent by an arrow so arrow points from a head to a dependent so now are they said some formal criteria for saying in a sentence if two words are connected what will be a head and what will be the dependent so there are some idea they may not be applying everywhere but may be applying it certain points so you will see some say examples for some of these so what are these criteria for defining a relation between head and dependent in a construction so first criteria you can see is that the head determines what is the syntactic category of the dependent or sorry what is syntactic category of the whole construction ok so like if i see this construction a letter the whole whole syntactic category governs simply by the word letter ok and that's why the head itself so the word letter becomes the head and this word letter can also replace the whole construction c so in place of the whole thing a letter i may also write simply letter now d specifies h so that means d is giving further specific information about h so i if i write only if i say only letter may not be as specific as saying a letter ok so all these determines they give some additional information similarly here ok so sent is the head and letter is the modifier so if i just simply say he sent it's not very specific to whom did he sent so there i have to specific particular modifier he sent her similarly what did he sent so there i have to put the word letter so what you are seeing the dependence is further specifying my head now in some cases so so head is always obligatory i need to put head like letter is import [ ant ] - is necessary to put but d i i may put it optional in some cases so i may also say he sent her a letter ok so so d the dependent may be optional in certain cases now the the word the head word it selects my dependent d and it also determines further the dependent is obligatory or not and in some cases the form the grammatical form the d takes will also dependent on my head so this is also ah called the agreement or government government in the case of linguistics so that ah so like the the form that use for your verb in in your construction will be similar to the form of the subject and object that we are using also with the linear position of the dependent is specified with respect to the head h so so for example so ah so english follows this as we are construct right so you get the subject first then the verb then the object so what we have seen the linear position of the of the dependent is determined with respect to the head so if i know the verb has come so i know subject will come to the left and object will come to the right like i want to say sentence where i am saying i am eating something who is eating the subject will come on the left i eat and what do i eat say an apple that will come on the right so the position of the dependent it is specified with respect to the head whether it is to the left or to the right now there are some cases that are clear where you can easily find the dependencies so so for example if i look at the exocentric and endocentric constructions what do i mean by endocentric and exocentric so endocentric construction one where one of the identity here can can actually fulfill the whole grammatical function of the whole of the complete construction so if you look at this verb and adverbial relation verb modifier so what is the example suddenly affected this may doing some grammatical function suddenly affected and why it is endocentric because only one word here like affected can fulfill the whole grammatical function for the whole construction suddenly affected suddenly is simply modifying that same way for non modifier like financial markets so markets can fulfill the grammatical function for whole thing financial markets it's not the case for exocentric construction like verb and subject so if i take affect and the news affected cannot fulfill the whole grammatical function for news an affected i need to have the word news so this is called exocentric endocentric one word can fulfill the whole function exocentric a single word cannot but the cases of exocentric what will become the head and what will become the dependent like if i have the verb and subject i know that verb will become the head and subject will become the dependent same way verb and object verb becomes the head and object becomes the dependent in the case of endocentric again the particular word that can fulfill the whole function can become the head and the other word can become the dependent so here verb is the head affected and suddenly becomes the dependent similarly here markets is the head and financial becomes the dependent now if you just try to compare what is the difference between a phrase structure a representation and dependency representation what we see is that in phrase structure we have very explicitly denoting what are the phrases these non terminal nodes and labels in the case of dependency relations what are the explicit denoting they are words but what are the relation between different words and what is the grammatical category of each individual relation so in the case of phrase structure i denote what are phrases and what are the structural categories like noun phrases verb phrases and so on in the case of dependency structure what do i represent what are the various head dependent relations like in the case of directed arcs and what are the functional categories that are what are the different arc labels that i am giving to various arcs in my dependent relation now formally can i define what is dependency graph so i have to define it for ah the words in my sentence so formally i can say that the dependency structure can be defined as a directed graph consisting of a set v of nodes and a set of a of arcs now this is a very generic way in which you define a graph in a graph you have a set of nodes and set of edges that are connected different nodes now is there something more than this in the case of dependency structure now in the case of dependency structure so this is the labeled graphs so what are the nodes in my graph the nodes in the graph denote the word forms the word that i that i am counting in my sentence and with that i might also have some ah annotations like what is the part of speech category of these words i can also put in my nodes and what are the edges they are labeled edges with the dependence relations what is the dependency time if it is subject object noun modifier verb modifier etcetera and some simple notations that we used for this is that ah if i am saying that word w i is connected to word w j with dependency relation d i can use this arc w i d w j it says that w i is the head w j is the dependent and d is the relation ok so i can say ah eat subject and i or he ok there is another way in which i can note the arcs by saying this is the headword this is the dependent word i am denoting an arc from a head to dependent word and putting a label on top of that this is another way ok and this is equivalent to saying w i d w j are in the set of arcs there are some other conditions like ah if i say that from i this relation from i to j direct relation then i can i can write that i j in my set of arcs so i am not writing the dependency relation here but i am saying i and j are in the set of my dependency relations similarly i can do a closure of this saying that i from i there is a there is path to j ok so that means in any number of steps i can go from i to j if and only if either i and j's are equal or there is some case such that i go from i to k and from k you can go to j any number of cases this is simple this is very standard way in which you define the closure relations so with the dependency labels i can define a single dependency or i can also define a closure of that so i hope this notation is clear so once we have this notation what does the total form of conditions that we can put on the dependency graph so on the graphs so that the denoted dependency graph for a sentence what are the formal conditions so what are the formal conditions so first condition is that the dependency graph that g that i get is connected ok by connected what do i mean there is ah there is no node in my graph that is isolated from the whole graph or in other words if i take any any word in my graph any node in my graph i can always find a another nodes such that either that node has an incoming link from that previous node or an outgoing into that node ok so it is connected to some of the node in the graph attached it's not isolated so this is the simple condition for saying when the graph is connected the second condition is that my graph is acyclic there is no cycle in the graph so what do i mean by that if i say that from a node i i have a label i have a path or i have a dependency from i to j there is no way i can have a path from j to i so there is no way i can go back to i if i am going from i to j i cannot go from j to i either directly or by following something k and this so this is not allowed ok so because this will make a cyclic i to j j to k k back to i so cycles are not allowed in the case of dependency graph similarly if i can if i can show the previous one that means that if i take a node i in my graph it should not happen that and they are connected and i is isolated i can always find some nodes such that either there is an incoming edge or there is an outgoing edge one of these they cannot be both right because of this principle of a cyclicity what is the third one third condition says that my dependency graph g obeys the single head constraint so what is single head constraint so single head constraint means if i take a node i in my graph they can be at most one head for that ok so if i say that j is the head for i so j is the head for i i cannot find another k so the k is also head for i this is not possible there will be only one head for i node at most is called the single head constraint and then finally we have the fourth constraint that is g is projective it says if from i i can derive j and from j so i am using the word derive here derive means from i ah i is the head and i have the dependent j then from j i have a dependent by some number of edges k for any k such that j k lie on the same side of i ok and this is the projectivity constraint and what do we mean by that if i were edge from i to j and from j i can have in any number of steps i going to k then j and k should lie on the same side of i so that is if i am saying this is my i and from here i have this relation to node j ok let me just project them i is here and j is here ok then what i am saying is that if j connects to any dependent either directly or indirectly that k has to be on the right hand side only so there are two possibilities suppose i am taking direct connection i can connect to k this is allowed or i can connect to a k here ok so this denote the linear order in the way they are occurring in the sentence so i and j are here so k can occur either here or here ok or anywhere else in the right but what is not allowed is if j is related to some k here that is not allowed because now j and k are on the different side of i ok so where whatever side j is k also should be on the same side and if so if this situation happens this is called non projectivity also there is another term for that it is called crossing of dependency edges so you are seeing here this line and this line are crossing here if i am if i am taking this particular constraint while they do not cross if i take this constraint or this constraint and you can see if you can go any number of steps they will not cross ok and this particular constraint is called the projectivity constraint now what is important is that this constraint of projectivity is a many times dependent on the particular language that you are choosing for your dependency construction so it might happen that there are certain languages that do not follow this projectivity constraint and some languages like english they very they quite regularly follow this projectivity constraint so this is like language dependent so the methods that the the dependency parsing methods that we will study in this week so we will study one method that that needs projectivity constraint another method that does not need this constraint ok so but yeah these four constraints are very very important so that you can come up with the good algorithm for a dependency parsing of the sentence so yeah this is an example of what is projectivity so if i have a link from a to b i cannot have a link from b to c because c is on the other side of a similarly if i have a link from a to b i cannot have a link from b to c ok because they are crossing in general what do they mean these four conditions so connectedness means that the syntactic structure obtaining my dependency graph is complete i am not having any isolated nodes that are not connected to my whole structure so in condition of acyclicity means that the structure is hierarchical there is no cycles inside what is the single head constraint it says that every word has at most one syntactic head it cannot have more than one syntactic head so or in other words we are saying it is determined only by one word not by multiple words right remember we were saying that ah the linear position of a dependent sometimes depends on the head so node one two different heads to decide the position of the single word and then they might be conflicts the same word has only one head that determines it's syntactic category and and in other things ah there is no crossing of dependencies that is the last constraint of projectivity that we also saw so now once we have these four constraints what is my dependency parsing so this is how i can define the dependency parsing i am given a sentence x that contains words w one to w n and i want to obtained a output as dependency graph given this input of sequence of words in my sentence i want to obtain my dependency graph that follows that constraint that we saw earlier ok so it is like single head constraint and ah projectivity if i am imposing that and all that so i want to obtain dependency graph so what are different methods that that we will be using for this so we will we will talk about different methods so like ah one method will be deterministic parsing this is a very very popular method then a method based on maximum spanning tree and finally you can also do it in a constraint propagation method so in this course we will talk about the first two methods and how you can use that by having some sort of labeled data and doing some learning from there so it's like a data driven parsing and the final method is something that you will use when if node have any labeled data but you know what are some of the constraints that your grammars follows so can you can you encode those constraints inside your dependency grammar and obtain dependency graph for a given sentence so this is good for the languages where if node have a labeled data but you have the labeled data in terms of dependency ah graphs you probably go for a data driven approach so starting from the next lesson we will start talking about this data driven approaches for dependency parsing thank you