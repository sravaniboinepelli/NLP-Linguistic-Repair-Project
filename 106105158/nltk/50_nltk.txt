welcome back for the fourth lecture of this week so we started talking about information extraction and there we discussed about the particular problem of relation extraction and we discussed some ah so one approach that is using hand built patterns so we can build some patterns manually and we saw that by using that we can extract certain relations between entities and there there was some limitations with that so we will now see some other approaches apart from hand built patterns so so you starting with a bootstrapping approaches so we we had talked about bootstrapping approaches in one of the earlier topic that is one word sense disambiguation but let us see how do we apply these approaches for the task of relation extraction so here so so you will use these approaches only if you do not have a lot of annotated data because if you have some annotations already available then you can use some supervisor approaches that might give you better else but suppose you do not have annotated data that means data where it is labeled entity one is related to entity two by a particular relation r if you do not have such data you will use your bootstrapping approach so so you do not have enough data but what you have r some seed instances of the relation and that is very easy now what they mean by seed instances so remember ah we were talking about hyponyms or meronyms see all you know some seed relation so you know ok basement and buildings are connected by the meronym relation car and vehicles are connected by the hyponym hyponym hyponym hyponym relation so you know some seed instances ok then what else do you need or you might have some patterns that you know and lots and lots of unannotated data so that means you should have a lot of corpus where you have a lot of text data it may be an an unannotated its a simple text data so so idea is using some seed patterns running running some idea over this whole data you can try to bootstrap your your approach for relation extraction so ah so the questions here are so suppose so here you have some seed instances so how do you use them for doing something meaningful or so that you can extract where is other entities so you have some seed ah instances how do you use that for extracting more more such examples and so this can be consider some sort of a semi supervised approach so what do we do here so let us take some simple example so ah here suppose i have my relation is burial place so x is buried in place y i want to find out all such entities that are connected by this relation so how do i go about it firstly i need to see if i have some ah seed instances that is some entities that are connected by this relation suppose i have an instance that is mark twain is and the burial place is elmira new york so i have this seed tuple now how do i start so remember what did we need we need some seed instances and a lot of corpus data so now you can use the intuition that how are you finding out ah the patterns in the in the case of hand built patterns so again we were starting with some hand with some ah seed instance so like basement building and we were trying to go to the corpus and seeing wherever these two words occur what is the ah what is the ah pattern in which they occurring same thing you can do here so you know ok i have two entities elmira and mark twain now you can search your whole corpus to find out where all all these two entities occurred together any single sentence or in some proximity now wherever they occur you try to find out in what pattern do they connect to each other and these patterns you can generalize as your gen generic patterns without having to manually go through each of these so something like so i have these and it is mark twain elmira and maybe i can google this google this google this entities mark twain elmira together and let us see what do i what are the kind of sentences do i get and suppose i get a sentences like this excuse me mark twain is buried in elmira new york this is the sentence and i know what am i entities here mark twain is x elmira is y so i can immediately from a pattern x is buried in y in this becomes my pattern the next sentence the grave of mark twain is in elmira so i can have this pattern the grave of x is in y similarly elmira is mark twins final resting place so i have this pattern now y is x s final resting place and so on so we are getting this sentence is from the sentence you are extracting over you are entities x and y and you are building patterns in terms of x and y so what you saw here just by using one seed instance and a lot of unannotated data you can find out some patterns now once you have patterns what you will do you will you will use these patterns to find out more and more such entity pairs that are connected by this pattern and that will enhance your seed seed tuples or seed instances then you can again use this seed instances to again such the corpus find out more such patterns and this can be done in an iterative manner until there is some convergence going on or you are seeing that there is not helping much so so now you have these patterns and you use these to search for new tuples so describe described by the simple flow chart that is you are starting with this some sort of seed tuples like mark twain elmira then you are searching with tuples in the in the corpus and you are finding various patterns and this becomes your pattern set you might also have some seed patterns already but you are getting some patterns now now using this patterns you are searching the corpus and finding more tuples and i putting them in your relational table and that is going to your tuple set now using your tuple set you can search these and find out more patterns and this can keep on going in many many iterations and this is in a very nice approach you can see that you only need data that is ah freely available everywhere and you need some very few seed instances and you can apply this algorithm and this does not require to do everything manually so yes but there are some problems with the that approach the problems for example are that the seed instance with which we start should be a good instance such that there are many occurrences of this seed in the corpus if the seed ah pair does not arrange the corpus you will not be able to extract many relations many patterns from this so this is one problem with this approach so this is sensitive to the original set of seeds that you use for your algorithm and in general there can be many parameters to be tuned for example how many top patterns will i take from from my set how many iterations i will go through and how many times i will send the same pattern for my first search there can be many a many parameters that you have to fix and yeah there is no such probabilistic interpretation so its difficult to know how confident you are in each pattern or each tuple that you are finding by this approach so here some sort of problems with this approach but it is a nice approach if you use to want to ah to get get it done without ah without building some sort of machine learning method also so on you can use this approach very ah for some simple ah and easy results but we will see if you want to build a more over system that what kind of approaches you can you can use so so for that we can talk about some supervised approaches for relation extraction so what is the idea so first you will ah define what are the kind of relations you want to extract so relations can be many like ok i want extract ah family relations so parent of ah wife of husband of and so on you can you can extract some ah ah organization relation this is an employee of and and subsidiary of and so on so we will define a set of relations now for each relation you will find data and label the data so they should be some manual labeling involved somebody has to label the data that ok in this sentence these entities are connected by this relation so you will choose a representative corpus where you think that there can be some instances of this relation now you will label the named entities in the corpus and hand label the relations between the entities so what will happen you have a corpus you will find out sentence s one s two s three s four and you say in the sentence this entity one this entity two and you know what is the relation between them similarly here you find ok there is one entity one prime entity two prime and there is some relation prime here and this has to be hand labeled why do you need hand labeling so once you have these hand labels they are like your ah so this is like your bold standard that you can you as your training as well as testing data so we will train train you are system using ok in in this sentence if these are the entities there is a relation between them so in a new sentence suppose two entities are there is there is the relation rel between them so this can be some machine learning model that you can built by using this gold standard and then you will ah yeah break into training development in text that is the usual practice in machine learning and then you will train a classifier on the training set so now so so here it might be one problem while you are using this approach in general they can be hundreds of relations and so you need to ah so so when in ah you are given a sentence between two entities take they can be many relations but they may not be any relation at all it might happen that two entities are occurring in a sentence but they are not connected by any relation there is no relation as such so what you might do is to have the first step that says ok in a sentence i know what are all the entities and this first step tells me which two entities are connected and which two are not connected and once you have the output of this step you know these two entities are connected then you run your additional classifier to find out what is the relation between them among all the hundreds of relations that you have so this issue this is seemed to be working in this in this area of relation extraction that first you find out what entities are connected second what is relation between them so its a two stage approach so so you find all pairs of named entities in a sentence and the extra a step can be build a simple binary classifier so that is says yes or no and it decides whether two entities are related or not and if you find an answer yes to this is step use another classifier to find out what is the relation between these two entities and why will that help because in the first step build itself you will be able to eliminate a lot of extra pairs that are not involved in any relation so we will not bother about those you will only bother about those entities that are probably connected by some relation other advantage could be you can think of the idea sort of features that you will used for the first step that is finding out if there is a relation or not and the second step that is if this relation what is that relation you can think of very set of features that you can imply both for both of these ah steps so here is ah one visualization of what this will look like so suppose you have this sentence american airlines a unit of a m r immediately matched the move a spokesman tim wagner said ok so now suppose by using the first step you found out that american airlines and tim wagner are connected by a relation ok so now you want to find out what is the relation so here you have a sentence two entities you need to find out what is the relation among all these pos possibilities is family relation citizen relation subsidiary relation founder relation and so on so lot of relations are there you want to find out what is the relation between these two entities now how do you solve this problem how would you solve this problem so you will have a lot of labeled data when you know these are the entities here and this is the relation between them so in classification what we do from this labeled data we try to abstract over some sort of features so we will say ok so these are the features that i see in this sentence and these features indicate relation one other sentence i am seeing this kind of features that indicating relation two and so on so this is what i i will i will have from my training data now attached data again i will try to find out what are the features and using these features i will try to match with with one of this previous examples i have seen in training data this is a simple ah this is simple illustration but it is generally more complex than that but this is the basic idea so the whole ah effort goes in deciding what should be my ideal features by which i can represent all my data points so so how do i say ok these two are connected by this relation what are the different things in the surrounding in the context about these entities that i should be using to to make this decision and that is your task of each engineering find out what are the features that will help you in this task in most of the application this is one of the ah main challenges that for this for this task find out what are the appropriate set of features i can used so we will see some examples at what so so here you can use all the different concepts that are covered in this course so its starting from simple ah language models part of speech tags dependency parse synthetic parse everything you can use to do find out to define what are your features in this task and you will see a lot of examples here and and this is ah one ah so if you want to build your own system you you might have to start thinking in terms of what are the important insight from data that i here use use as in the form of my features so remember features are something that that you think can help me ah discriminate between various relations here so it can help me tell me tell if this is a family relation versus if it is a citizen relation what are the different things that can help a are these various words that occur in the context are these part of speech tags and or or this is a something else so this you can abstract in terms of here features so let us see what are the kind of features we can use for this task so i have the sentence american airlines etcetera and my initial features could be what are the words in my mention m one and m two so m one is american airlines m two is tim wagner so what are the words that i used in these two mentions so feature here can be bag of words features so mention one use uses words like a american airlines and mention two uses words like tim wagner so these are simple features i can also use what are the headwords of these two mentions the headword mention of of of mention one is airlines and for mention two it is wagner and you can also see what is the headword mention of one plus two airlines plus wagner so why you are using this headword kind of features so here you are having american airlines but suppose there is something like indian airlines or or some other air airlines so by using the headwords using capture e one a new ah new word that has the same headword but the the initial word was different it can be captured by using headwords same with tim wagner so you are capturing the surname here by headword but suppose if someone else has a surname wagner so it can also be used then i can use a what are the words that are coming around the mentions so that is what are the words are coming before american airlines after tim wagner and what are the words in between so what can be my features so words or bigrams in particular positions left and right of m one m two like what is the word before m two so its a spokesman what is the word next to ah m two that is said ok so what you are abstracting here i have an entity before which i have a word spokesman and next word is said so the new context whenever i see what is spokesman before what said afterwards it might indicate that there might be this relation ok a spokesman x said it might be a good indicator of this relation you can also use the back of words or bigrams between the two entities that is what are the different kind of words that occur between the two entities here so we will say ok so words like a m r immediately matched a spokesman unit etcetera they are all occurring between the two entities and they all go as you are features so you can have named entity type and mention type features so for example what is the named entity tag for the mention one so its like american airlines organization so this you can get by using various ah named entity recognition tools you can run in any are and you can find out what are the various named entities so its say ok mention one is in organization similarly mention two is a person so this can be nice ah feature that can help you this is in organization this is a person so what can be a relation between them and yeah it can be together also what is the named entity for one in two together organization person then you can also find out entity levels of mentioned is the name nominal or pronoun so here first one is a name second one is also a name but suppose in the sentence you have it he etcetera so we can call it as a pronoun on the other hand if you have a word like the company you will call it as a nominal so all these can also be your features now suppose you want to use the dependency between them so you will see when you convert the sentence to a dependency graph what is the connection between the two entities what are the different branch in that in the tree are connected so suppose you find this dependency graph so we will see ok so they are connected by this path matched said and you are saying going to wagner airlines matched said wagner so now you will try to use certain features based on this path also ok so it can be maybe what are the words that occurring in this path or what is the complete path altogether so here what is the headword of of the dependence the dependency headword for word one so you had ah airlines matched airlines is the dependency for the word one for headword two so we have the dependency said and wagner this can be a feature immediate dependency feature matched airlines said wagner then what is the path airlines matched said wagner and and you can also think of some other features ok what is the label they are at in that dependency graph how many different words they are connected to and so on and then you can also do chunking and is use used features like ok if you chunk them you will find american airlines a unit of a m r etcetera and your feature could be what is the chunk in which it participates what is the next chunk after this and so on you can also use the constituency parse feature so you have the two words here american airlines and tim wagner and this is the party of the sentence so you can use the the the path from here for noun phrase to this particular noun phrase that connects tim wagner so what is the path here going to an noun phrase to a sentence to a sentence to a noun phrase this path can be helpful again here you can use what is the label in the tree they are at and what is the sibling and so on so these can be your various features then they can be some ah sort of features that you can obtain from various gazetteer and ah different terms kinship terms so if your relations contain mother of and parents of an all that so you can use some kinship terms so like parents wife husband grandparent etcetera and this can be obtained from various electrical sources like wordnet also and then you can use various gazetteer like what are the cont country name list so you can see ok so the next word after the entity one is a name of the country or the previous word after the entity two any of a country similarly for names of very famous celebrities or persons all these can be used as your features so so this is the idea that that you have this task you have to find out the relations and you you should be able to use whatever sort of features you think will help in this task so we are seeing we are using a lot of different sort of features and so and they are using all the different concepts and topics that you have seen in the basics of this course so you can have country name list others of entries etcetera so now once you have identified what are your features so what will happen if youre training data each instance you can convert in a feature vector so we know what are the different features that are that are involved in this particular sense and then you have you can use various classifiers to built ah to find out given a new sentence how do i find out if the two entities have a relation and what is the relation and then you can you can use multiple classifiers like naive bayes classifier or s p m or maxent etcetera and this is the rule always you train on the training set tune on development set and test from the test sets so you should never use your test set for building your features or ah whatever ah patterns so you should never use it as set you should be kept separate so you will only tune on your development set if you your training set you run your classifier and ini initially test on the development set if it doesnt work keep on improving and once you are satisfied then the on the test set and find the accuracy and you might also have to compare with others if you want to find out if you are doing something better than what people have already done so now how do i so once you have done this classifier you will get your ah so classifier will tag in this sentence these two entities are connected by this relation and so on now how do you find out how good your system is performing ha and how we compare with the system so for that we will talk about what are the various ah evaluation measures or evaluation metrics matrix how do i evaluate it ok so in standard that evaluation metrics are what is the precision what is the recall and what is the f major so how do i define these what is the precision recall etcetera so here are the simple definitions so precision is so for suppose i am doing it for each relation separately so precision would be what are the number of correctly classified or extracted relations divided by total number of extracted relations so that is ah suppose my system ah is giving ok so these entities these pair of entities are connected by a relation r ok this is the output of my system now from a gold standard suppose i know that this this and this is correct and this is incorrect system will give four output three are correct so precision here will be three by four so this is one very important metric that my system should have a high precision it should be whatever relational predicting should be correct what is the other criteria so the criteria is recall recall is what are the number of correctly extracted relations but my system identified divided by total number of gold relations now its important to find the see the distinction between that two so ah what we will do in re recall so the system output in requires the see what is the what are the gold standard relations supposing my gold standard i had five entities i know these entities are connected by this relation and suppose my system has found out so it has found out three it is found out this this and this but my system could not find out this and this so what is the recall of my system my system could recall three out of five possible relation so recall here would be three by five ok and this i can do for every relation independently and i can show my system does work for this relation with this precision this recall and so on now there is also a a metric where you can combine these two and that is called f measure and what you do is to take a some sort of harmonic means so this is two p r divided by p plus r you will take a harmonic mean of precision recall and that is called your f measure so this is f measure two p r divided by p plus r although there are variations where you can give different weights to precision and recall also but this is quite accepted measure that you give a equal weightage to precision recall and find out an f one measure so now if we try to summarize the supervised relations extraction task what we did here so ah so in general it can achieve very high accuracy for some relation and if we have lots of hand labeled training data so for most of the machine learning algorithms they all depend on how much label data that you have so if you have lots and lots of data they can give you better better and better accuracy so so that is one bottle neck also so you need to label lot of data to be able to get good accuracy and so this is the limitations here so labeling large training set and the entities mighty be very very expensive and it may not generalize to different relation so i have labeled for some relations but suppose i want to now extract some new relation i cannot use this label i need to get new labels for the new relation so whatever i have labeled the the model will only be able to extract those relations a new relation i have to do the labeling again so this also does does not generalize so so we sought to approaches in this lecture we saw bootstrapping you have you do not want to annotated lot of data here some seed instance you go for that but you can if you can annotated lot of data then you can use a supervised approaches and they are the main problem is ah after labeling find out interesting features that can help with this task now in in the in the final lecture for this week you will see an interesting approach that blends these two approaches together bootstrapping and supervised approaches and this can also generalize to many many different relations that that you have so we so this is take this approach is called distance super provision so in the next lecture we will talk about that approach thank you