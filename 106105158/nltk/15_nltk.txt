so welcome to the fourth module of the of this week ok so so as we said last time we will be starting with a very very popular problem of part of speech tagging if you remember this was one of the processes that we talked about when dealing with morphology so you can do lamentation you can do morphological analysis you can also tagging so what was the thing that was that was different in tagging that you are not doing morphological analysis if you remember you will also finding out among all the possibilities what is the actual ah particular morphological degree that this four things so you also doing the disambiguation here ok so this is my problem of part of speech tagging that given a set of words ok so that means a sentence of document whatever can i identify what is the actual category for each of the word i have to give the unique answer for each one so each one so if we take example for english text so given a text of english can be sentence or whatever can identify the part of speech of each and every word that is the problem of part of speech tagging so so if i have a sentence like the boy put the keys on the table and i have four possible part of speech tags so very very ah coarse label like noun and pronoun v for verb and p for pronoun the first p here is for prepositions and d det for the determiner so you can map the is a determiner and boy is a noun put is a verb the is a determiner keys a noun and on is a preposition and the is a determiner and table is a noun so each word you can map to one of the four one of the four tags so this is a problem that given a sentence you have all the individual words can identify and define what is a in grammatical category for each of this word so now ah so one one natural question that you might have is ok so how many different part of speech tags are there ok so firstly let us see what are the different things that will go in the part of speech part of speech tag categories ok firstly you will have the open class words ok that are sort of content words so they are like nouns verbs adverbs adjectives they are they are there they will have their own part of speech text so they are the the open class words are those that we are the content mostly and so why do we call them open class because you keep on adding new and new words ah in in the language we have coin ah we have seen a term for this right so you have words like google photoshop skype they come into the language all so these are coming into nouns or verbs in the in the language so this is open class you can keep on adding new and new words and then you have the closed class words like pronouns here very fixed set of pronouns determiners very a fixed ok then prepositions connectives and all that they are very fixed they are all functional words and they are closed class ok and as you know they are they are used to tie various concepts the sentence together ok so i need some part of speech categories for open class words some categories for closed class words so one possibility can be i can choose very very coarse grained categories right like here so i can take noun so i am also giving some examples here like chair bandwidth pacing all these are nouns i can take verb study debate munch all these are verbs then adjective like purple tall ridiculous they are adjectives adverbs unfortunately slowly proportion of by to they become my preposition pronoun i me mine and then determiner ok the a that those so maybe i can just use it very very coarse label ah part of speech tags but think of the perspective when a of language pronouncing so what is helpful to me to take a very coarse label or to go to the more fine grained label so here what will happen i can find out which word is a noun but if i to tell it's a singular noun a plural noun i cannot tell if i have even if i have the tagging information so i might want to prefer a tagging scheme where i also go to some sort of grammatical details of the word ok it is a noun ok and and is it a verb is it a the third same person singular verb is it it is a verb plus a past tense and so on even noun is it a proper noun so i might want to go into finer detail but again i cannot go into very very finer details so again they ah otherwise there will be too many part of speech tags so there are various ah is schemes that are available so they have their own part of speech tags definitions so but given a sentence if you have to do part of speech tag tagging you need to first defined what is your tagset what is all the possible categories among which you have to choose it and there are various standards available ok so yeah i can choose very very coarse tagsets like only taking noun verb adjective adverb or i can take a good enough set that gives me some additional grammatical information with each of the word each of the word ok so one for very popular part of speech tagset is university pennsylvania upenn ah treebank tagset that contains every forty five part of speech tags and we will see examples also and there is a very nice tutorial on these part of speech tags in terms of ah how what is the difference between this part of speech tag verses at part of speech tag particle versus adverb how are they different by giving examples so that i recommend as if you want to get more information in in the sense of how they are used in various sentences you can look at this this site so here are some examples of ah the treebank the upenn treebank part of speech tag so what are the part of speech tags they used and what are the various sort some example words here so for example in this if i see ah conjunction so and but are all j conjunction they they give a tag like c c one two three we are cardinal numbers they give a tag like c d a da det they are determiner give a tag of d e t then additional there foreign word then off in by they are preposition yellow adjective then bigger so again with adjective you have comparative superlative so you are add adapting some more information there let's start a marker now if you see at the nouns ok you have a tag n n for only the noun is a singular noun a masculine sorry it's a singular noun ah for plural noun you have a tag like n n s ok if but now you see there an extra text for proper noun you had separate tags so once you know the tag you know it's a noun or it's a proper noun and whether it is a singular or plural you get all this information so that is the that's why getting it into some finer details is helpful so you have four different text for nouns similarly so if i am escaping those i am going to the verb directly so here text like v b for the base form of the verb then v b d for the past tense v b g for gerent v b n for past participle and then third singular present is v b p and third singular ah and is like v b z ok non third singular versus first singular there are two different forms so you have different forms of verbs so again that they give you various grammatical information and then you can see other sort of part part of speech tag that are available in to upenn trees ah ah tag tagset so let's take an example then so we have taken a taking a sentence and if we tag it by upenn tagset how does it look like so the sentence is the grand jury commented on a number of other topics so now here the word does determiner grand jury adjective ok so jury would be a noun commented becomes a verb so you have seen the part of speech tags on is a preposition i n a is determiner number is a noun of is a again a preposition other ah adjective and topics they come in noun in plural form ok so this is the information that you get by the part of speech tags now the question might come come that why are you worried about solving this problem of part of speech tagging it is a hard problem or a trivial problem can i define for each word in my lexicon what will be it's part of speech tag it is a very very simple problem no so so the problem occurs because each for does ah does not have a unique part of speech tags and it might depend on the context in this the word is being used ok so so what i am saying is that a word might have multiple part of speech tags and only by seeing the context you might be able to identify what is the actual part of speech tag is being used in this particular context so let's take an example so i have the word like back ok so what are the part of speech tags that this simple word like back can help so if i take the sentence like the back door what is back here what is the part of speech tag of back so it is an adjective now if i take a word like sentence like on my back it's not an adjective anymore it becomes a noun in this case yes now i have it win the voters back of the sentence it becomes in win back ok so it becomes in adjective and if i have a sentence promised to back the bill now this becomes a verb ok so the same word back can be used in multiple part of speech tags so so immediately you can see the problem that given the context find out what is the appropriate part of speech tag is be used ok so to determine the part of speech tag for a particular instance of a word is my part of speech tagging problem ok now what are the various ah information that we can use for doing this for how co how common is this first of all how common is this problem how how many words are actually ambiguous in terms of part of speech tags so if i see if i want to see that from the data ok so so this is your this so this point i just want to say something like once you encounter problem in in in language or any other field the first thing that you might want to see is that how common is that problem if it is a very very rare problem maybe it's not worth to spend too much time you can have simple rules for solving that but it says if it is a very very common problem then yes you might have to tackle it using certain models so similarly here the disambiguation part is speech tags so then it happen only for ten words if it happens for only for ten words i did ah need not worry about building some models and all that for solving this problem but if it happens for say ten percent of the words then yes there is a real problem and i need to ah think of some model for solving it ok so now if let us see from the corpus how common is this ambiguity problem so if i take the brown corpus so what we see here forty percent of the word tokens are ambiguous and twelve percent of the word types ambiguous so i i hope you remember the distinction between types and tokens tokens are the all the passes all the occurrences of different words so same word occurs multiple times are multiple tokens ok so forty percent of word tokens are ambiguous so what we are seeing saying is that in a corpus if i am encountering and tokens forty percent of them are ambiguous that's a huge number forty percent of all the words that occurred in the corpus ambiguous ok so that means the real problem now if we want to just break down of the ambiguity type that how many ah unique words have um different number of tags so what we see here so roughly thirty five thousand types have only one part of speech tag now three thousand seven sixty types have two tags and two sixty four have three tags and so on and there is one word like is still that has got seven different part of speech tags in the brown corpus so so yes getting six seven tag is very very rare but getting two and three tags is quite common especially two tags is very very common in the brown corpus now now the next problem so we have solve that this problem is ah frequent yes this is not a real problem but how bad is this problem what do i mean by this so can we always identifies for a given word is one tag more likely than an another so let's take an example of the word race race can be a noun and a verb when the brown corpus race at race occurs as a noun ninety eight percent of the time but as a verb two percent of the time so if i have a simple model that always assigns the word race to a noun that will im immi immediately achieve a ninety per eight percent accuracy write for this particular example at least so that means whenever i am trying to design a model i should be able to think of what is in what is simple baseline uninitialized compare if i'm making computational model that is working even worse than this baseline it may not be very very helpful ok so respite this can be my simple baseline for testing any of the model that i will propose for this particular task so so a tagger for english that simply chooses the most likely tag for each word can achieve good performance so it can be ah even more than ninety percent ok so so always it's not good to look only at the final numbers it's also ah good to see how much you are improving over maybe some of the simplest baselines and some other models that that are there in in the literature so at least the simple baseline how much you are able to do better than the simple baseline say an any new approach should be able to should be should be able to compared against the simple baseline now how do i decide the correct part of speech tags so yeah one thing is a it might even be difficult for people in some cases right it's not a very very easy problem always so here in this slide we have three sentences this is shaffer never got around to joining all we go to do is to go around the corners and chateau petrus costs around twenty five hundred ok and all the three words three sentences you have the word around and you will find out what is the part of speech tag ok and you will see this is not very very easy if you will just ah look at these sentences is not easy to find it what are speech tags so i will just suggest that you go to the tutorial once and so the tutorial that i i talked about earlier so that all talks about what are the differences between various part of speech that will give you some idea on how to find out the actual part of speech tags of around in this case so what we will see here before in the first case it is a ah the particle second case it is a preparation and third case it is in ah adverb ok now what is the relevant knowledge that we might need for this part of speech tagging problem that we might need to give to our models ok so for example some words might always be in one part of category like arrow is always a noun so i can have this knowledge some words are ambiguous like fly flies ok and what like like it can it is again ambiguous so what might help is what is the probability that a word occurs at a particular as a particular part of speech tag the baseline that you are talking about this might be helpful for our model also that given a word what is the most probable tag for this word this is one thing that we might use now what is the what what can be the other information that is useful so take the word leg flies ok if you do not give me any other word i may never be able to tell with full confidence what should be the corresponding correct part of speech tag unless you tell me the sentence where it occurs ok same was with the word like saw that was one of the earlier examples ok unless you give me the sentence like peter saw her i cannot tell the saw is actually a verb and not a noun so that means i need i need to do something of the word itself how come how common it occurs with some part of speech tag then another i also need to know about the context in which the word is occurring and how can i use the context to desegregate the actual part of speech tag so so i need the local context in the sentence so for example the information that to determiners really follow each other so if my model is saying two words the determiner determiner which is not allowed ok similar two based forms of the word they do not follow follow each other they they should not come together similarly ah my model can tell me that a determiner is always followed by an adjective or now this can be useful information that if the previous word is a signed determiner it is a highly likely the next row will be adjectives or noun so all this we want to encode using our models as well so what are the various approaches so so we will try to use all this knowledge but what are the various approaches that we can use so for all the problems that we will be is dealing with in this coarse mostly you can always use a rule based approach ok so so this visual some of the earlier models that work that were used in n l p so we are given a problem some language will sit together find out what are the symbol patterns or sing simple kind of if then else rules that one can write down to to solve this particular problem ok so what would be a rule based ah solution to this problem ok for doing the part of speech tagging disambiguation problem so what i will do i find out for all the words that can have multiple part of speech tags what is one particular thing that that can help me decide whether to use one tag or the other ok and this and given a new context i can again use this is is that particular ah contexts appearing here or not then i can have a statistical tagging that is i get a training corpus ok so this is a standard model so i have a corpus training corpus that has the tag text by tag text i mean i have the sentence and with each word i also have the actual part of speech category now using that can i learn what is the actual part of speech tag for each individual word and this ah in a new sentence can i learn some model so this is my statistical tagging so ah so they are again different variation different various models so one simple model is ah t b l tagger that was one of the earlier model proposed for part of speech tagging so that is i am given a any corpus of tag text can i learn some sort of transformation rules that this word has a particular main category most probable category of part of speech tag but given the context if this most probable text should be changed to some other tag so can i use some rules from a corpus training corpus itself and then the probabilistic models where i will i will have a probabilistic in the position of what is the most likely sequence of tags for a sequence of words so we will go go through t b l tagger very very briefly and then we will devote a lot of time on the probabilistic taggers so what is t b l tagger transformation based learning so let's try to understand the idea first so i have a sentence like the canvas rushed it ok so how the model will process so this is my training data set so i also know what is the actual part of speech tag for each of the individual word now if you the first thing you will do is to find out for each individual word what is the most likely part of speech tag so in other words the can was rested ok so if you find out a more slightly tag for the word can it will be a model work and mostly occurs as a model work ok similarly rush ford rusted it would be a verb in the in the past tense that is the most popular ah probable tag so i will write down the can was rested ok now i will see in my actual training sentence what are the actual ah or thus rejected are assigned to different words so i find this is correct this is incorrect this i am sorry this the most probable tag will be m d moreover is incorrect in this and as i will have a noun this is fine but this will be instead v b n is a participant past participial ok so these two are incorrect so i need to write some moves so that these can be transformed so one symbol can be m d changes to n m sorry to n n when preceded by d t remember the rules that we saw in the previous previous lecture so it needs to be if preceded by something and there is nothing so we are not putting any restriction what is being followed so this is a rule that i can use so now what will happen in a new case whenever a word is assigned m d if i see the previous word is determiner i will change m d to n n ok this is the rule i am running from this example similarly i can rule a learn ah learn a rule here v b d goes to v b n whenever preceded by reading this can be another rule so this is the idea i have training corpus i find out for each for what is the most likely tag whenever they do not match i will write down some set of rules and then i keep on doing that and i might put down a separate data set simple small data set for testing how good my finally tagger text so this is my t b l tagger ok so this is what we have seen now what is probabilistic tagger in probabilistic tagging i will have a probabilistic interpretation of what is the most likely sequence of tags that should be used for a ah for a given sentence so let me just briefly talk about what in general the probabilistic tagging models to so in these models we have some data that is some observations d and a certain class ok so in the case of part of speech tag what is the example of d n c so d are the words and then tags are my classes i want to assign various classes that that tags to different words so tags some a classes now you take a different problem like text classification what will happen the documents all the sentences if you are doing classification or documents a sentence is they become your data and you have your classes so suppose using sentiment analysis so the sentence is your data and the class is positive negative or neutral if you are doing text classification in terms of a sports visage politics and so on there is categories the document or the vertical instance of the text becomes your data and that becomes your class a sports and politics and so on so you have a paired observation of ah a data and a class now they are two ah different families of probability models that can be used for solving these problems ok i will just briefly talk about these two families and we will take a examples from both of these for this problem ok so and and you will be able to use that for many other applications n l p also ok so what gives raise to two different families that is whether you generate the data from the class or the class from the data so what is the philosophy of your model ok so let's try to ah understand that from this ah so so from this slide so we have two different types of models one is a generative model and and second is a conditional model so in generative model what will happen so you have appear data and the class so generative model you will assume that the class is there and the class generates the data ok so this is the philosophy from the class that it i generated so examples are like nigh page modular hidden markov models so your class is given and data generated from this in the discriminative condition models what will happen that your data is there and you assume that hidden state is a generated from the data so that is the the minor difference between that so in the condition in the joint model you first at the class you first generate the class and then you generate the data from the class ok so that is so so to give a simple example if you want to use a joint for generating modules for text classification what will you assume if i am going to take a document i will first think over what is the topic i want to write say politics i think about the the class and i am given this class what is the probability that i write all these words ok so from that class i find out the probability of different different words so i that's how my model is defined in the case of conditional model given the observation directly i want to find out the probability of the class ok so so so this difference tells me whether so how do i actually go about solving these models ok so ah so they are the models like s v m s perceptron that are ah not probabilistic so they are not in division one of these so they are also discriminative classifiers now this picture will help you understand that two models again so you see the directions are different in the in the pic pictures in the first direction in the first in the left hand side picture so direction is from the class to all the data points ok so first the class is generated then all the data points so you generative model in the second one is a conditional model so given the data you want to find out directly the probability of the class ok so first one example is nalve bayes second one example is logistic regression ok so so a joint model will give you probability of so d l the data and the class together and you will try to maximize the joint probability and condition of mo model you will directly want want to find out the probability of the class given a rate ok so we will take examples of both of these in the in the next modules so what is a ah joint model that can help me solve the part of speech tagging problem and what is the condition model that can help me solve the part of speech tagging problem ok thank you