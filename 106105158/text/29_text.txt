 welcome back for the third lecture of this week so in the last lecture we had defined what is the notion of our transition based parsing and we we saw what are the configuration that i should i should have what are transitions i can take and how do i come up with a final dependency graph and we took an example and showed what are the transitions you can take and how you should be taking the transitions and then we ended with saying that how i will be using that for getting parse for a new sentence ok so this is something that we had ah initially asked so i have some sentence s s i can find out what initial configuration is why the function i keep on taking some transitions go to some intermediate configuration until i obtain terminal configuration and i said with the data i will have some sentences and their corresponding dependency parsing and from there i will try to learn what are the operations of transitions i am where to take now in this lecture we will see for a particular problem how we will be doing the learning part so again let me start by giving you the basic intuition so what will be the basic intuition so in the last lecture you had learned that for a sentence if you know the dependency graph so this is my labeled data if you know that you can run through the steps very very easily the steps of transitions so you can say that this is my initial configuration and you can find out what is the transition i should take say it is shift so you can store somewhere this is my initial configuration c zero and this is the transition then by taking this transition you will go to some other configuration c one what is the transition it may be left arc ok again some c two it can be shift and so on ok some c m it can be shift or something so this given a sentence you can easily run through these steps and find out and what is this c i c i is nothing but a some words in stack some words in buffer and something in my arc that is my c i so that means suppose i am given a set of sentences and their dependency graph i can store all the possible set of configuration and all the possible by all the possible i mean whatever i obtaining from these sentences and their corresponding transitions ok and this i can have a last set so i will have a set of all possible c i and that optimal transition that i should be taking and c i's of this form something in stack and something in buffer arc now what is my problem at run time at run time i am given a sentence s i do not know it's dependency parse ok so i start my transition i converted to some initial configuration c zero that is easy of the function of converting to initial configuration there i have to find out what is the transition i should take now what will be the idea i will try to use this set of ah data that i have i know for what configurations what transitions word taken in my gold standard or in my ah set of labeled data set so i will try to find out so before going into what this is the machine learning ah approach we will use so what will be intuitive idea try to find out what are the closest configurations in the set and for those closest configurations what transition was taken and i will try to use that t star from there suppose i find out the t star is the transition that was taken to the closest configuration here so i will use t star and once i know this t star i can transit it to next one c one again the question will come what is the transition i should take so again go back to this and choose t dash take this go to c two keep on doing that until you will come up with the final configuration c m and that's why you say this is the dependency graph for s and this is the intuitive idea in the last lecture we have seen how do come up with this set and today we will see how do i how do i approach this problem so that i can come up with this function that what is the closest configuration from here to here what is the transition that i should take it so so one important idea that we had already discussed earlier in this course is that for example how do you find out the closest configuration and what is the transition that we are taking this you have to use by using a some sort of classifier that is you are trying to classify for a given configuration among all the four transitions which transitions will be taken so you are as a four class classification problem at each point you are trying to classify among one of the four classes and how are you going to classify you have to convert your input data in some representation so this will be using some feature representation so you will have to convert your configuration into some sort features feature vector and for those features you have to learn the weights and this weight you have to learn by the training examples again and once you have learn the optimal weights you can find out what is the transition at at any given point and this is what we will be discussing in this lecture so let us see so now we are talking about the data driven deterministic parsing so so i have written here certain things like deterministic parsing requires in oracle what do i mean by oracle so oracle is nothing but the set of configurations and the set of transition that i took ok so this you have already seen in the last lecture how do you find out configuration and transitions now what we are going to do we want to approximate it by a classifier so we will be learning classifier from there and it will be trained using the treebank data so whatever data we have in the gold standard label data we will use that to train our classifier also so you will use that label data for two different tasks first for building the ah oracle configuration transition configuration transition second to learn the weights of my classifier ok now what is the learning problem now as we said we will be given a configuration as a input and we want to find out what is the transition i should be taking at a particular configuration so ideally i want to approximate the function that takes a configuration which is represented by a feature vectors two transitions so configuration to transitions here configuration is nothing but a feature vector form because otherwise how do you compare between two configurations so that's why you will take give it a very exact representation in terms of ah some feature vector form and you will learn a function from feature vector to the optimal transition and this is this will be your classifier and how will you learn that you will be given a training set of gold standard transition sequences that we already have seen so now to completely solve this problem or to completely understand this problem there are three issues that you need to understand first is how do i represent configuration by a feature vector second how do i derive training data from my treebanks and third is how do i learn my classifiers so let us try to answer each of these three questions so how do i represent configuration by by feature vectors and this is something that we had done earlier in the class that how do i convert a a given state or represent to a feature vector so what is my configuration my configuration is nothing but a stack buffer and arcs and i want to convert that to some feature vector and feature vector again here we will take it a very simple form like f c t it is a function over the configuration and the transition and we will try to define features independent of transition so each feature that we define can have four copies four four different transitions so f c t one f c t two f c t three f c t four like that so so what are the different things that i can use in feature so i can use things like what is the word at top of this stack what is the word at top of buffer they are very important what is the word here then i may want to use what is the part of speech tag of these words because sometimes some relations would might might directly dependent on whether it is a verb and it is a noun then there might be a relation otherwise not so i might use the part part of speech tag i might go to the lemma i might want to use what is the distance between this word and this word in the actual sentence i might also want to use what are neighbors here i might want to use what are relations that i have already been established with this word or this word ok so that means i will define certain conditions over stack buffer and arcs and that will i would like to take my features and again these can be some binary questions that i am asking so that is is the distance between these two words between two to five yes or no ok so like that these can be my condition that is my features and i will define it for all the four transitions so let us look at what are the different feature models we can take in general so i am representing configuration c by a vector of simple features so like i can use the nodes so what is the top of this stack what is the head of buffer i can use the linear context that is what are the neighbors in s stack of the top word what are the neighbors in buffer of the top word then i might also use what are the parents children siblings depending on what relations are already been established in my set of arcs then i can go to some other attributes like i can use the word form i can use also it's lemma and we can use them up part of speech tag and various other features for example is the is the word on top of stack ends with e d or i n g things like that and i might be able to use the dependency type if i am handling a labeled dependency problem so so yeah just a word what do i mean by labeled dependency problem that means i also want to find out for two words what is the dependency relation label and if i am solving unlabeled problem that means i want to just want to establish a relation but i am not concern with the actual dependency type so i am not worried about putting the label on the arc but just the structure of the tree so if i am solving label problem i might also have to see what is the relation type that i am establishing and we will also see the distance between different tokens as one of the features so these are some typical examples but it doesn't mean that you are limited only to using this set of features and as i keep on seeing for your particular task you might have to think what might be some interesting features that you you can use so by using all these features i am putting my binary questions i can represent my configuration as a in terms of a feature representation so this is my first question now what was the second question now how do i use this at run time but actually find the ah parse of the sentence idea would be something like that so let me start from here at run time you are given a sentence w one to w n ok and you can always go to the initial configuration where the buffer is sorry s stack is empty buffer contains all the words and arc is empty ok now this is your configuration and you are in a loop while the buffer is not empty you keep on taking some transitions now this is the task say run time so this configuration c you know how to covert to the to a feature vector because you are defined your features so you can ask the questions at this point and find out your vector f c t now what is my classifier my classifier is simple i have learned the weights of my features assume that i have learned we will see how to learn the weights so once i have learned the weights of my features i will multiply the weights with f c t and find out what is the particular transition that is giving the maximum value that means i know what is my f c t feature vector and i know my this is my f c t and this is my weights so now at run time i am given a configuration c and i need to find out what is the optimal transition how do i do that an idea is that i will multiply w with f c t i for all the four transitions so t i is shift left arc reduce and right arc and i will take which one gives the maximum value argmax over t i so at run time any configuration i can convert to f c t very easily i will already have the weight vectors the only thing that i have to do multiply the weight vector with the feature vector find out four different values four different transitions choose the maximum or choose the transitions that has gives the maximum value that is the transition you will take and then if you go back this is the transition you take and then apply this transition over this configuration to find the next configuration and keep on going in this loop until your buffer is empty and this is what your run time now what is not clear to you right now is how do we learn these weights right everything else is clear so let us see so so learning weights we will have to use the labeled data that we have is the training data now let us see what are the steps that we need to do over the training data now training data i will have the instances of this form f c and t is this clear entering data we will have configurations and transitions yes and configuration i know what is the feature representation so i convert the feature vector so i can have f c and t f c is nothing but the feature representation of the configuration c and t is the correct transition out of ah it starting from c and this i can for obtain from my oracle remember in oracle i had my configuration and the optimal transition so i know this configuration what is the transition it should take so from there i go to next step f c and t ok now now this is something that we have done in the last class but let me try to repeat that again that how do we sample this oracle function from the set of labeled ah sentences labeled of dependency graph so for each sentence x with the gold standard dependency graph g x you have to construct a transition sequence right like we did in the last class for the example he sent her a letter such that c zero will something that will obtained by applying the initialization function on on x and this is the final dependency graph ok now for each intermediate configuration we will construct a training instance so right we will have c i t i c i t i and c i will go to f c i and this is the condition for how are am i moving in from one configuration to another configuration so this is the same thing that that i have discussed earlier in today's lecture that what is the idea is starting from the gold standard sentence and dependency graph find out this sequence c i t i c i t i now the only addition here is i covert each c i to it's feature representation so that's why i what i have i have f c i t i f c i t i and how do you sample ah the transitions in oracle this is something again that we did in the last class so if you see that in my dependency graph the current top of the word in the stack is connected to the top of the word in buffer so you will have a relation depending on the direction it will be left arc or right arc so here if the top of the word in buffer is the head and this is the dependent you make a left arc transition so this is what you will store if top word in the in the stack is head then you will have a right arc relation yes then how do you choose between reduce and shift if there is a word below that of the stack such that it is connect to the first word in the buffer then you do reduce otherwise you shift and remember this is that we discussed in the last lecture if you are between reduce and shift this is the condition that you can use so ok so so i hope the the idea is clear you are starting with the sentence in training data you have the gold standard dependency graph you keep on going through your transitions and store it somewhere f c i t i f c i t i f c i t i now how do i use that to learn the weights now and this is the idea of learning the weights so so what you will do you will start with some initial set of weights so so here i have said all the weights can be initialized to zero but probably not will zero you can initialize with some other numbers say ah some initial random numbers or some uniform numbers you initialize your weights with now what are you going to do so there are two loops here for i is one to k this is the number of iterations that you are doing for j in one to n one to n is the all the set of sentences that you have in you are training data so you are doing multiple iterations over your training data in j iteration what do we do you take the sentence yes you get the initial configuration fine now while buffer is not empty so so what you are doing right now you are again repeating the same stuff over each sentence in the training data ok you start with the initial configuration and now try to find the transition as per your current weights so so that's where the idea of learning comes in so let me try to explain it here so so you have a sentence s s now you can apply the c s x function or and you go to initial configuration c zero now you take a transition to go to c now this is your sentence in your training data that means you know what is the transition you should take yes but i want to use this idea to learn and how do i do that now suppose that you are actually at the run time at testing time so then you do not know the transition so you will convert that to some feature vector f c t ok now it run time how do you find out the optimal transition multiplied with the weights and take the argmax and let us say this is t star this you can do that even if it is in the training set and let us call it t naught optimal transition now what is the idea you are still in the learning stage so your weights will not be optimal so when you do this operation you may not get the optimal transition you may get something else and that's where you will try to adopt your weights so you will say if t star not equal to t zero then you update your weights and how will you update your weights such that you go in the direction of the actual transition and away from the transition of the the transition that you obtain at the current point so simple thing is w new would be w old plus f c t zero minus f c t start so going in the direction of the optimal transition and away from the transition that you are currently ah predicting and there can be some learning rate and all that we are not ah discussing right now so there will be some learning weights by which you will do this update so you will have now new weights again you keep on doing it for c one c one you know what is the transition optimal transition but you will find out argmax t start match with this if they are not the same you will again update your weights so you will keep keep on doing that for all the sentences s one to s n in your training set and you will do it one two some k times until the weights are converging so once the weights converged we stop so this is what we have shown here so you start for each sentence you have some initial configuration while buffer is not empty so you keep on doing the stuff find out what is the optimal transition as per your weights find the optimal transition from the oracle if they are not matching update your weights but you take the correct transition so the next time you are starting with correct configuration keep on repeating it and finally you will end up with new set of weights ok so now to further understand that let us take a an example and that will make it clear to you that how the learning or how the weight updation takes place so so this is simple example so i have a sentence john saw mary so what do you need to do first question is draw a dependency graph for this sentence that is very easy yes now the next question says that you are using the data driven dependency parsing the same method that we have discussed in this lecture and in the last lecture and you already have the gold standard parse in your training data and you have some other information like john and mary are nouns and saw is verb and also given you features and you are told that initialize your weights to five except that for left arc the weights are five point five define your feature vector and the initial weight vector so let us try to do this so how many conditions are we seen we are seeing three conditions over my configuration the stack is empty top of stack is noun and top of buffer is verb top of stack is verb and top of buffer is noun three conditions now these three conditions i have to check for all the four different transitions so how many ah what is the size of my feature vector three into four twelve so my feature vector so it's of twelve dimension and what are my features so first feature let me write it simply condition one that is the stack is empty and same as starting with left arc transition is left arc second feature can be condition two and left arc third condition three and left arc yes this is my f c t a condition over the configuration and transition first three elements next three elements same c one but now transition will change still right arc c two right arc c three right arc and then the next elements c one reduce c two reduce c three reduce and here c one shift c two shift c three shift so this is my feature vector twelve elements here now what is my weight vector initial weight vector we said all the elements are zero sorry are five except the left arc is five point five so the weights are five point five five point five five point five and everything else is five point o five point o and so on that is your initial weight vector and your task is now so this was the first question what is my dependency parse john saw mary so saw is here john and mary this is subject and this is object now let us see what what the question says further so the next question the question says use this gold standard parse during online learning and report the weights after completing one full iteration of arc eager parsing so it says that now you have to learn the weights using the arc eager parsing or the transition parsing that we have seen so ok so now let let us see how do we learn the weights so so this is what we have defined right now we have this features we have this weights initially as per dependency graphs so how will i start learning in learning i will take this sentence i will put it to the initial configuration initial configuration is what this stack is empty buffer contains john saw and mary and arc is empty so now at this configuration c i have to choose what is the optimal transition as per my classifier and i have to choose the optimal transition as per my oracle from oracle what will be t zero oracle i will be very easily saying that this would be shift i am doing a shift at this point i should shift here but what is being predicted by my classifier so let us see what will be t star as per my classifier so for my classifier how do i obtain t star so t star would be argmax w times f c t for all possible transitions so let us do one by one so what will be f c l a what is the feature vector when the transition is l a so for that let us look at my feature vector definition so this will be a binary value at each point c one and l a what is c one top of the stack is this stack is empty so c one is one and transition is left arc so this will be one c two top of stack is noun and top buffer is verb now top of stack is empty it cannot contain a noun so c two is zero so already this will be zero c three again say top of stack is verb and top of buffer is noun again this will be zero ok that's why i fill in my my feature vector now let us go to this now immediately as you move to some other transition r a this should be zero yes because here your transitions is l a so everything else will be zero twelve elements ok now what is your weight vector weight vector is here say if you multiply weight vector with f c l a what do you get so w times f c l a is equal to one so only one element is one so i will multiply with that this will give you five point five ok now similarly now you can easily figure out what are the other features f c r a for r a similarly only this element will be one everything else will be zero so what is w times f c r a that will be five and similarly if you keep on doing for all shift and reduce you will find this for shift is five and this for reduce is five yes so now what is your t star argmax t w times f c t that's will be left arc and what is your t zero optimal is shift as per your oracle and how do you learn your weights if t star is not the same as t zero you will update your weights and what is the late update w plus f c t zero minus f c t star so what is f c t zero that is f c s h so what will be this function so suppose so s h was at the end so it was one zero zero and everything else is zero and this is my l a so what will be the new weight vector so i have the original weight vector that is this one plus this minus this so what will be the new weight vector it will be i am i am subtracting one here so four point five five point five five point five five point zero five point zero five point zero five point zero five point zero five point zero and now i come to shift in shift i am adding that one so it will be six point zero five point zero five point zero and that is your new weight vector ok and now you will verb with this weight vector for the next set of configuration so what will be the next configuration from here you will apply shift and next configuration will be john saw mary and phi again you will convert it to the feature vector see what are the what is t star that you are getting what is t zero if they are not matching update your weights and that you will continue until you arrive at the terminal configuration and then you will have the final weight vectors so i i encourage all of you that you should try it this full example on your own and see what is the final weight vector that you are ah getting and even if you are trying to see that by using this weight vector does that help in that now with the new weight vector if you try it on the old configuration you will actually attain the you will you will be closer to the optimal configuration as per the oracle and not what your classical early updating so so this is the idea of how you can use the machine machine learning methods for this dependency parsing by taking this example of arc eager of transition based parsing now in the next lecture we will we will start discussion on a new method of dependency parsing and we will see that again how we can use the label data for for doing this ok thank you