 so hello everyone and welcome to the second lecture of second week so ah in the last lecture we talked about what is the basic edit distance concept given two strings as input what is a dynamic programming algorithm that you can use find out what is the edit distance between these two strings ok and remember we we we define certain operations certain edit operations and we gave weights or cost for each of these operations but all these cost for equal ok so the if you are substituting a a character by another character irrespective what is the what are two what are the two characters the cost remains the same same goes for for inserting a character it the cost remains same and also for deletion of a character it remains same so in this lecture we will briefly discuss that is there any way in which we can try to ah discriminate between various sorts of ah edit operations firstly is this should we discriminate between various operation should there we assigned the same cost or should be try to give different cost and different operations then we will also talk about the practical problem that given a query so why query i mean a term that might be incorrectly spelt how do i come up with list of terms that are actual that for actual terms that should have been used instead of the the incorrect so what what should be in what is a good or efficient algorithm to find out all the set of terms that are variation of edit distance of safe edit distance of one or two of that query so so starting with the concept of weighted edit distance so can we weight the the edit distance cost depending on what are the characters that are involved in the in the operation so firstly is it required so so do you think substituting a by e should have the same cost substituting a by m so what should depend on ok what kind of so for example there are certain errors that you make very very commonly and certain errors that you make very very rarely ok so now suppose you co error is very very common should i assigned it a higher cost or a lower cost so think about it what is what is it mean to a assign it a higher cost assigning it a higher cost means that the edit distance between the two strings will increase if that edit operation is present ok so that means the probability of obtaining the other string as a candidate we will go down if the operation as a high cost but if something is very very some some sort of edit operations are very very common some spelling mistakes are very very common we want we would like to give them a lower cost so that i can the actual candidate have a small edit distance with the incorrect word ok so it is important to understand what kind of ah characters will have a lower edit distance and what kind of character will have a higher edit distance can be somehow give a weight so so so this is the basic idea so why do we need to add various weights to the computation so the idea is that some letters in a language are more likely to be mistyped than others ok so let us take some statistics so this is a confusion matrix for a spelling errors that was found in a corpus so x is the incorrect character and y is the correct character ok so what is what is this stability is going how often in that corpus they found an incorrect x for a correct y so for example if you try to read the table the the entry for the first row the anti corresponding to a e that means how many times instead of the correct e and incorrect a bar substituted and that number comes up to be three forty two ok so that means in the corpus three forty times at an instead of e a was written similarly one hundred eighteen times instead of i a was written similarly seventy six times instead of o a was written ok on the other hand if you see b it never happened that a b was written as a so that means people make the mistake of converting or instead of writing e writing a this is a very very common mistake on the other hand b two a is not very common ok so so you can look at this confusion matrix and you will find a lot of nice patterns so one thing you will see is that the errors among the vowels are very very common so substituting i for e e for i a for o they are very very common ok so there may be because the person is may be not knowing the spelling or so is even if you knows the spelling by mistake is typing the other verbal so this is ah this is also possible now there are some other kind of errors that you can see here that come because of the way keyboard also designed ok so the you will see the the characters that that come very very close in the keyboard so sometimes you miss type them ok so this is again a common source of a spelling error so for example m and n are very very close together and they also sound very similar so it is very likely that you you mistake m for n or n for m so that is this kind of errors are very very common so so some errors come come because some of the characters sound very similar so like the all the vowels or certain characters and also some characters are very very close in keyboards so so that is again another source of errors so now once we know that some errors are more likely than others can i use that this statistic to design my weighting scheme so as i said earlier if some error is more likely the addict cost from one character to another character should be low so that i can easily find what should be the actual candidate given in the erroneous word ok so the smaller edit distance means that is more likely to be the correct candidate that's why we will give a smaller cost to those spelling mistakes that more likely and in larger cost or a higher cost those spelling mistakes that are not so let that are very very rare see so keyboard design is again again one thing that gives rise to many of the errors that we have seen in the previous slide ok so again try to correlate among the characters that are coming very close in the keyboard so we will see that many a times people make mistakes in typing one character for another so now suppose you have some data and by analyzing the data you can find out what kind of errors are common what kind of errors are rear and accordingly you can design your weights for different ah different ah edit operations so now once you have each weights that depend on the actual characters you can modify your initial algorithm ok so how can you modify your algorithm so for example here so i will so if you if you try to compare this with a algorithm that we saw in the previous slide small reference here is that we should have giving a uniform cost for deletion insertion substitution what we are doing here so deletion is now ah conditioned on the actual character that is been deleted ok so you see d i g zero is d i minus one zero plus a cost for deletion of x i so what is the cost for deleting that particular character same goes for insertion what is the cost for inserting that particular character even in substitution you might have cost for so that separate cost for deletion insertion and substitution of one character by another ok and everything else remains the same the only thing that changes is that instead of using equivalent cost for each operation you are now giving cost that are dependent on the actual characters that are inserted or substituted or ah deleted so that is my weighted edit distance so now so what to do you do with so how do you modify your algorithm for taking care of transpose for instance ok so that is the algorithm were we had the we had three operations we had insertion substitution and deletion they were three operations that we why we are using in that ah in that previous operation so there is another very common edit distance operation that is used and this is called transpose so that is if i am ah so if i am transposing toward two characters and you will receive this is a common error that sometimes you make ok so for example so i am wanting two type a l and instead i typed it as l a so this is called transpose so in general if i write x y as y x so this is called transpose another name for this is metothesis so now how can i modify my algo algorithm to take care of this case so till now we have three operations insertion deletion substitution in insertion i see the the previous insertion deletion i see only till the previous word ok but what do i do in the case of transposition so in the transposition i will have to so because it is ah we have go to characters before so i need to go to d in my cos matrix d i minus two j minus two yes and suppose i give a cost of one for transposition ok so i will write ah d i j as so there are other cost that we had defined earlier but for transposition i will say d i minus two d i minus j minus two plus one and what will be the condition only if so the previous word in x so ok so i i had defined my strings as x and y here ok so this is my string as x this is my string as y so what will happen here this is up to i so this x i minus one will be same as the jth character in y so if x i minus one is y j and x i is equal to y j minus one ok so if i find that so x is still i is and y it's will j so if i find that the i minus oneth character of x is same as the jth character of y and the ith character of the x is same as the j mines oneth character of of y then i will say that this cost is d i minus d j minus two plus one so again i will do a minimum of this this if this happens this is my transpose and then they i have other conditions for insertion deletion and substitution and that's how i can modify my algorithm by initial algorithm to also include transposition ok so with all these operation this is the only other operation that is also commonly used in computing edit distance so now so so we talk about edit distance and also about ah doing including another edit operation like transpose so as i said earlier so we will also discuss briefly so so what is the practical scenario so the practical scenario here is your given an input word ok so remember in the introduction slide we two are talking about this error ok say wold cup and by mistake i i have written w o l d instead of writing w o r l d so now the practical problem here is once i know that this is not the correct word in my vocabulary how do i find out what are the possible candidates that might come in place of w o l d so that is what are the suitable candidates now as per our definition so the suitable candidates are those that are having a small edit distance from the actual error word ok so intern my problem is how go i find out words that are within some a small error some small edit distance of word so now how do i solve this problem given a word like w o l d find out all the words that are within the additions of say one or two now one simple thing you might says that i will list down all the words by vocabulary somewhere ok so i have all the words in my vocabulary starting from w one to wn ok and i will find out what is edit edit distance of w one with world w two with world and up to wn ok i will find out all the edit distances and then i will among those i will choose all those that are coming up to the very very small edit distance some some top entries that are coming out to be within a small edit distance so i will find out this type of entries ok this is my candidate so but you but you you can immediately see that this may not be a very very efficient solution ok because my vocabulary size can be quite huge and i have to find out edit distance from this to each of the words in my vocabulary so that will be really really time consuming ok so instead can i so can i do something more efficient so one simple thing is i should try to search in an efficient data structure for searching all the words in my in my dictionary ok so so in case you do not know so so one of the very efficient edit structures that is used for searching the strings is called the trie structure ok so using the trie structure you can do search efficiently in the linear time so linear in the length of the input string so i am giving you one example here so so i can use the trie structure so so idea is that so you you take any word you can start from the initial root node of this trie structure and keep on following the arcs and in the time linear to the length of your word you will reach to a node and find out if the word is available in the vocabulary or not so by that you will able to search all the words in the vocabulary and this trie structure can be used efficiently for computing the distance of any any new word with a word in this in this trie so this is one possibility but this again it requires you to do a lot of computations with respect to all the words in your vocabulary what can be other possibility so other possibility if your thing would be so instead of trying out to find out the ah edit distance of this error word to all the words in the dictionary can i start from my error word and try to enumerate all possible words within some edit distance ok say one or two ok i am trying to enumerate all the possible words edit distance one or two so i will find out the word like world and everything else and then i can have a further check to see if these words there in my dictionary and all and there i can use maybe a trie structure that whether these words are available in my dictionary or not so this can of the possibility now what is do you see do think this will be efficient this approach so let us see some some numbers ok so yes so i can possible generate all possible terms is starting from the error word that are within edit distance of less than equal to two and there i can take care of all the deletion substitution addition and transposition i can try to take care of all the possible ah edit operations so starting where wold i generate all the possibilities with the edit distance of two now so if you just try to do it's a simple math try to compute how many different possibilities you will have to explore so let us see so suppose if you take a word of length nine that is nine characters and suppose in you are taking a language like english and alphabet is thirty six so and so that twenty six plus other ah other characters and if you just do that so this will give you roughly one hundred fourteen thousand three forty four three twenty four different possibility to explore staring from the word of length nine in which of the four you think will give you a lot of possibilities ok deletion will probably not give you many possibilities but substitution will give you lot of possibilities and insertion should also give you lot of possibilities substitution you can substitute each character by and you have a thirty six characters so that gives you a huge number of possibilities so this is again huge number so it's starting from a word of length nine you you are going to explore hundred fourteen thousand three hundred different possibilities ok but yeah english is still ok so you have thirty six characters so think about a language like chinese where the alphabets size is seventy thousand so you cant even think of applying an approach like that ok so this is an approach is slightly better than then before but it is may not be very very efficient again depending on the alphabet size so what can be the other possibilities ok so other possible algorithm is that ah the idea that all this all ah all this edit opp edit distances can be attained if you try to do a symmetric delete from the the current word and the possible candidate words ok so all the edit distance of operation two can be found out just by doing deletes in both the words ok so what is the idea so this is called the symmetric delete a spelling correction so idea is that from your query word and so from your query word you will try to find out all the words that come up within delete of two from the query word and from your dictionary for each of the word you will try to find out all possibility that come within and edit distance two as per only the deletes and that this will cover all the possible variations of edit distance of two ok so you can we can take a simple example so suppose i so let's take the same example of w o l d or so even or we can try to take a a different example say w o t l d instead of w o r l d that is the correct word and this is the error word ok so what we will do is symmetric delete operation so this is this i will do offline it's an offline a starting from word i will store all the possibilities within edit distance of one and two so i will store with world that there is word w o l d that comes up w o r d and so on and from these again you will have this is delete one and you will also have again candidate for delete two at run time when you get this query like w o t l d that is incorrect you will do the same thing so this is at run time and you will again generate all the possibilities with delete of one and two so we are doing here one only to show the possible possible so you will find w o l d w o t d and so on and now you will try to match if one of this is available in this dictionary that is that is built by this symmetric delete operation and you will find w o l d and w o l d is a match and once this is a match you will go back to the original word and then confirm that this word and this word have a edit distance of less than or equal to two ok and and that's how you can find out all the possible words within edit distance of two without i am doing a lot at run time now can you tell why because you only doing deletes at run time and deletes a not mind ok so if you do one delete if you heard of nine characters you have only nine possible deletes so this is not very ah inefficient at at at run time and this all is done at offline and later you will have a further check to see that these two words have additions of two if your two or three sort so yeah if you take ah number of deletes of two for a word of length nine it will be at most forty five so this is not a very big number so this is one approach that that you can that that you can use for finding out all the possible dictionary terms within some edit distance efficiently at run time ok yeah so now so when we talk about edit distance and some variations so we will not focus on the task of spelling correction with which we had a started this module on edit distance and all so so when we talk about spelling errors there are two kind of errors that you might have to deal with so one that are easy to to handle errors so i will say slightly easier they are called non word errors because they are at so the erroneous word is not in my vocabulary so in this case so erroneous word is b e h a f that is not in my vocabulary i can deduct decision erroneous word and my task is to correct it to the actual word b e h a l f behalf and this is also called non word error ok what is slightly more difficult is something called a real word error when the the word that is in error is also in my dictionary but somehow the user has missed spelt to a word that is in my in my dictionary so here some examples so like typographical error so instead of writing there somebody has write a three now three in my vocabulary so it is not easy to that the this is in error now correcting this is called a real word error correction similarly they can be something for because of the homophones ok because of say piece and peace the two different variations of pieces you might misses spell very very easy and t o o and t w o is very very common error so they are also called real word errors now to handle both both of the ah non word error and real word error you need to use various probabilistic models ok and this is what we will be focusing so ah in non word spelling errors so the non word means the word that is not in my ed edit dictionary so any word that is not in the dictionary is called an error ok and so for handling this problem it is better that you have a good very good lexicon tells you all the possible word in you lexicon and this lexicon may also be dependent on the particular corpus that you are processing ok so for you if your processing scientific coppers you might have different corpus then if you are processing use corpus so you should know what your words in the in the dictionary and when you encounter word that is not in your dictionary you will tre treated as a errors and try to correct it so what in general what you will do in non word spelling correction so starting from the error word you will try to find out candidates that are similar to the error word and how will you define the similarity with respect to the error word so you will say the words that are within form a small at a distance ok that can be that can be one possible criteria and if you are using noisy channel model that will be the topic for the next module so you will see the one that is coming out to be as per the highest noise and probability so this will be your candidate words so you will choose some of the candidate words like that on the other hand if you are dealing with the real word spelling error you will try to find out so now you have the you did not know in the sentence which of the word is actually erroneous so what you will do for each word you will find out other words that are similar in edit distance or some other criteria but in the candidate you will also include your actual word so so t w o is there so we include t double o also with two and you say that the actual sentence might contain any of these two words ok and then finally you will try to maximize the probability of the sentence using some noisy channel model so this is what we will be discussing in the next next lecture so where we will talk about noisy channel model in detail and how it can use for doing the task of spelling correction so thank you