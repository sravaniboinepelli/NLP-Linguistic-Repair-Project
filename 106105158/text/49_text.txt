 so welcome back for the third lecture of this week so in this week we are doing some advanced topics on text mining and so tutorial we will so this lecture we will start with information extraction so we will see what are the basic ah so all the basic applications where information extraction will be used what kind of techniques you can used and we will focus our attention to a specific task that is relational extraction how do i find out relation between any two entities by using the text corpus on the web so what do i mean by ah information extraction so so we can say that the goal of information extraction is like machine reading so you have a lot of text available on the web it's all on the um unstruct unstructured form there is no particular structure to that now from that text can i obtain some structured knowledge that can be used for various different applications and tasks ok so this is like a ah some sort of caricature to to to denote that that yes we have a lot of knowledge available on the web and machine is trying to go through the knowledge and get some a structured content that can be useful so ah so what the information extraction systems do they try to find and understand various different relevant parts of the text data so so what you will have you will have a lot of text and you are trying to get a certain important information from there and so we will see what are the various ways in which you can gather this information so now now from this all this data that is available what you want you want to get a structured representation of some sort of relevant information and it can be like various relations in the sense of database so you can find out what are the various entities involved in this text and what are the relations between those entities and can also be some sort of knowledge base that you are constructing from the data so ah so the goal of information extraction is that we organize information so that it can be useful for two people for ah for doing some of their tasks and we want to put information in a very precise form that will allow um need to make further inferences ok so remember this was one of the things that we are talking about in the introduction also that the natural language text is not very precise so how do you make how do you convert the information to something precise that can be used for doing various task and various inferences and that's what we we doing in the in the case of information extraction so this is a simple definition that you can get this is a sort of working def definition you will say so so what is information extraction so that is task of finding a structured information from unstructured or semi structured text so you have the corpus or data that you have is either completely unstructured ok so i can think of various treats various cora questions answers and lot of web pages sort of unstructured or it can be somewhat semi structured where you have some more information like extraction information ah headlines etcetera but this is not completely structured so from this unstructured or semi structured data i want to find out a structure information and that's what it's the definition of my information extraction so so now question comes in that what sort of information do you want to extract from here so information can be something very very ah clear and factual like for example this is this is ah this is something that that is normally done so they should like who did what to whom when and who is in what relation to some other entity and and so on so for example suppose you have some newspaper text and they talk about various ah earnings profit headquarters etcetera and this is one one of the company report the headquarters of b h p be billiton limited and the global headquarters of the combined b h p billiton group are located in melbourne australia ok this is some sort of ah unstructured data that you can say ah in the form of the sentence now from this data you want to gather some structure information so what kind of structured information do you get from this um text so you will see that so what are the headquarters of b h p billiton limited so then you know the location here melbourne australia and this can be some sort of a structured information that you are trying to gather from the simple sentence and that is what your information extraction system can do so from here suppose you get this information headquarters of the b h p billiton limited are in melbourne australia since out of relation form there are two entities and there is a relation between them and this you are extracting by using information extraction now what is the so what is the use of doing this extraction so once you do this extraction you will know all these tuples so you will know this two entities are related are related by this relation and so on and over there you can do lot of queries you can do lot of inferences and so on this can be very helpful for many question task also another example let us say we have the sentence in nineteen ninety eight larry page and sergey brin founded google ok now from this sentence what kind of information you can get so who are the founders of google and when they find when they found found google so all this information can be extracted from here and put in a very a structured form so like i can have a information like founder of larry page google founder of sergey brin google and founded in google in nineteen ninety eight so all this information is there in this text and this can be extracted by a using information extraction systems so now once you have this information it can be used by various search engines and database management systems to provide better services to the end users it is not very trivial to do it directly by using the text data but once you have this in the database form you can you can do a lot of different tasks and look you can use a lot of different tools to to make each of this information so now what are the various applications of information extraction for example biomedical domain so in biomedical domain you have a lot of ah research papers that are published that give details about what about the various experiments that were done using and using various ah patients and what was the findings of those experiments and what kind of drugs work what kind of drugs does not work they can be various clinic clinical clinical trials they can be various patrons and all that lot of information is there but this is already very unstructured form so so suppose i need to look for discoveries that are related to various genes proteins or other biomedical entities so and and then the problem here could can be that these entities can have various synonyms and there are lot of ambiguities involved so what is the task i need to automatically identify what are the mentions of biomedical entities in the text i find out ok these are that entities that has mentioned in the text and then i want to link them to their corresponding entries in the lexical database suppose i have a database that says ok these are all the all the different biomedical entities now in a research paper i i need to find out ok this entity talks about this is corresponding to the per particular entity in the database this is very similar to the entity relenting problem that we discussed in this week itself now once we find out various entities in in the document other task here could be that i want to find out how they are related to each other so this is called relational extraction that is one of the focus of ah the next three lectures so so this is an example so you have this ah research paper in biomedical dome domain and this is research paper you also get some abstract now from this abstract can you extract information in a structured format like p fifty three is a protein bax is a protein p fifty three has function of apoptosis and so on now all this information is available in the text data but not in this very nice structured format so from from there can you extract these are the entities and this is the relation between them so here so you find what are the entities and with different ah between various pairs of entities what is the relation and this is called the structured knowledge extraction and this the analogy is shown here so the research paper extract can be thought of as a as a if something for humans and this structured knowledge means can be thought of as something for machines so machines can make use of this information for various tasks now another example so this is like a report that that you find on the web and from this report can you extract various relations so here you have the sentence american airlines the unit of a m r immediately matched the move a spokesman tim wagner said so from here you can find out the tim wagner region is a spokesman for american airlines and suppose your relation is employee so we can say tim wagner is employee of american airlines also american air airlines is the unit of a m r so you can have this relation american airlines is a subsidiary of a m r ok and similarly here united a unit of u a l you can find out this relation again so from this huge amount of text data can you find out this is a structured information so that is the task of information extraction find out the entities and what are the relations between them another example so when the relation can be were also very very generic so like you can be personal relations like married to mother of organization relations like a spokesmans for president of artifactual owns something invented something produces something they can geospatial relations that this city is near to this city this city in the on the outskirts of the city and these kind of relations might be very very helpful in ah replying to various queries they talk about that need geography information see you know what cities are nearby other city so you can try to answer these kind of questions and directional relation this is southeast of and so on and they can be part of relations so you need of something parent of annexed acquired for this political relations so you can think of lot of lots and lots of different relations that can be established between entities now using these relations you can do lot of different ah ah some sort knowledge engineering you can do a lot of inferencing you can try to answer questions and and try to predict certain relations between the entities there are lot of different tasks that you can use once do you can do once you have this structured information so now so the topic here is how do we gather this resea[rch]- information ok so there are like ah i would say like in many different n l p applications so here also there are five different methods for doing this task so one simple method is you choose your hand built patterns then you get it bootstrapping methods you know supervised methods distance supervision is a very very nice idea that you will see for this particular task and then you can also use some unsupervised methods so we will focus on the first four methods and we will see ah clearly how you can use one of these methods for the task of information extraction so let us see what we do in the hand built patterns so idea is you can use various regular expressions for finding entities and the relations between them so suppose you want to find the entities so here so this is ah for noun groups it's simple regular expression so regular expression you can also ah denote by using a finite automaton so here you are seeing a finite automaton that is denoting a regular expression and this so what it is denoting any noun group so let us try to follow this so you have this ah phrase johns interest interesting book with a nice cover this is a noun group so how does this automatic capture this you say a pronoun a personal noun john johns ok interesting becomes an adjective book is a noun with is a preposition a article nice adjective cover noun and this is a it is a final state so this becomes a noun group so we will see even john is a noun group and johns interest interesting book is also a ah noun group so it is trying to capture nouns group noun group in various sort of granularity you can even have single word you can have multiple words so you it is telling you what is a noun group now you can further extend it to find out ok i know what are the noun groups now what is the relation between that so suppose i want to find out which person holds what position in what org organization so what kind of patterns i can think of a person x holding position y in organization z so suppose i have to use some hand built patterns how will i go about it so i will first think about what are the various kind of sentences where ah all these three entities can can occur together so there will be a person who is working in an organization so and then once i have found some sentence is i will try to abstract what is the normal pattern that i am seeing here so for example one pattern can be person comma position of organization because you find sentences like vuk draskovic is a person comma position leader of the serbian renewal movement ok so now what you are abstracting here there is a person position and organization and now you can think of many many many such ah sentences where all these these three entities will be there in this relation so once you identified this pattern you will give this pattern to the machine and from there corpus it can ah extract all these entities for you and you will know immediately that these entities are connected by a particular relation what can be other ah patterns so like organization named appointed etcetera person preposition office ok again they are all these entities so nato appointed wesley clark as commander in chief so we are finding again all the three ah entities in a particular relation so similarly suppose your task is to find out where is an organization located so we will think about what are the patterns something like x located in y and or y is xs headquarters so we will think of these patterns and using these patterns you will try to extract these pairs of x y like organization location nato headquarters in brussels so we will extract nato headquarters and brussels are the two entities organization location and you can say division branch headquarters like k f o r kosovo headquarters so you know this is the observation and it's a location so like that you can think of various patterns and extract these relations and this is one of the very early examples on how these kind of patterns for used for extracting hyponym relation so hyponym which is you remember it's a relation between sub concept and a super concept when these words ah first um given by hearst so what is the basic intuition suppose you are seeing this sentence agar is a substance prepared from a mixture of red algae such as gelidium for laboratory or industrial use this is sentence now suppose i asked what is gelidium and you can say ok ah gelidium is some sort of algae or red algae from the sentence yes now how do you know that gelidium is a red algae see you are seeing some sort of pattern here red algae such as gelidium ok so this pattern is telling you that gelidium is the kind of red algae now you can try to abstract these pattern in you say that whenever you are finding such patterns x such as y there is a hyponym hyponym relation between x and y and this is the idea find out many such patterns and from these patterns you try to extract these entities so what has did he found out various search patterns where you can have two entities connected by hyponym relation ok so ah y such as x is for hyponyms so what are the other kind of patterns you can use such y as x ok like such vehicle as car such vehicle as bicycle ok x or other y yes car or other vehicle car and other vehicle vehicles including car and and so on ok vehicle especially car so this i am given example with car and vehicles but you can think of it as with any hyponym hyponym pair so he found out freddy such titles and from these patterns he tried to extract the hyponym( Refer Time: 19:00) hyponym relation from the text data so here are some examples for these hearst patterns and the what kind of example occurrences you can see in the data so the pattern x and other y you can see temples tragedies and other important civic buildings so from this sentence you can immediately see that ten percent treasuries are sub concepts of civic buildings so we can have this pair of hyp hyponym hyponym civic build civic buildings are the hyponym and temples is the hyponym similarly treasure is the hyponym x or other y so bruises won't broken bones or other injuries so we can have all these as a hyponym of injuries y such as x so the bow lute such as the bambara ndang so here you can see that ah bow lute is the super concept this is the sub concept such y as x such authors as herrick goldsmith and shakespeare so immediately you will see there is a relation here and so on y including x y especially x so hearst hearst manually found that all these patterns and from these patterns he was trying to extract a hyponym hyponym pair piar from the data similarly ber berland and charniaks they found out some patterns for meronym relation that is part of relation basement is the part of building so they were trying to find out ah patterns for for meronyms so again you can think of what are the patterns that come to your mind so so like buildings basement so you will think of some example and see what kind of sentences they occurring buildings basement basement of the building and so on and you will try to make patterns out of these so so let's take these two simple examples so like i am seeing that i have an example basement and building ok and this is my suppose my x and this is my y and i want to find out many such x y pairs that have the same meronym relation so how will i start i say ok in the sentences how will baseman in building occur together something like basements building sorry buildings basement so it will be y's x buildings basement ok or basement of the building x of the y and so on ok and these are now my patterns ok and then you will try to see in my corpus where do all these patterns occur so example is cars wheel wheel of the car so we will see ok these x y are related by this meronym relation and that's how you will try to so we are in these patterns we will try together many such x x prime y prime pairs ok so what berland and charniaks did they selected some initial patterns for finding all sentences in the corpus that contain basement and building ok that's a normal ah is a nice method of finding these patterns so then they found like buildings basement basement of a building basement in a building basements of buildings basements and buildings and so on now here they were writing down the patterns so here something like n n so they were writing in terms of what is the parts of speech that is coming and and so on so of preposition so parts the plural noun of preposition wholes n n it's a plural noun so this is part in whole relation ok part coming as n n in between there is the word in as a preposition the or a as a determiner and in some modifiers so there are now here abstracting so what they are seeing ok ah basement in a building but it might be basement in a huge building right so how do i absolutely better than i say ok there is in optionally they can be in adjective here so that's why they are saying j j or n n is star basement in a civic building and so on all these can be captured by slightly ah generalizing these con these patterns so that's what you are seeing here j j or n n so you can have a civic building huge building and all this will be captured here so like that you try to find out these patterns and using this patterns so once you have these patterns you try to extract some other entity pairs that are ah involved in this relation so now so this is a nice method if you want to sit down and and look at each and every relation and and think about the patterns and that's the that's also the problem with this approach that some some persons who are ah good with the data who are also language they know how how the system work they can they can they can try to get you some hand built patterns so now question the problem is that they are hard to write and hard to maintain and there are like you can think of zillions of patterns so we can think of so many different ways in which people can talk about hyponym hyponym pair in the in the data so how do i capture all of these patterns manually and yeah there might be domain dependent so every domain you might have different ways of writing things and yes you you can do that for some relations but suppose they are thousands of relations how do you do for all these thousand relations and yeah so we and these patterns that hearst found or berland and charniaks found they were giving ok kind of results but they were not like giving very very accurate results so for example hearst patterns give the roughly sixty six percent accuracy on hyponym extraction and berland and charniak gave fifty five percent accuracy on meronyms so we would like probably prefer to have better accuracy than these numbers so so so that is using hand built patterns you can only go little so only small distance and there there are also a lot of manual effort is required so how can we avoid this manual effort and that's what we will see in the other approaches that we will be discussed it starting from how do we do simple bootstrapping here ok and that's all you will be discussing in the next lecture thank you